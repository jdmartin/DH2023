<?xml version="1.0"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
		<!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
		<title>A deep learning approach to Cadastral Computing</title>
		<meta name="author" content="Sofia Ares Oliveira , Isabella di Lenardo , Bastien Tourenc , and Frederic Kaplan"/>
		<meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
		<meta name="DC.Title" content="A deep learning approach to Cadastral Computing"/>
		<meta name="DC.Type" content="Text"/>
		<meta name="DC.Format" content="text/html"/>
		<link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
		<link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
		<style>
 div.dh2019 { max-width:1000px; margin: auto;}
 body {
       font-family: verdana;
       font-size: 11px;
}
 p {
    font-family: verdana;
    font-size: 11px;
}
</style>
	</head>
	<body>
		<div class="dh2019">
			<img src="https://dev.clariah.nl/files/dh2019/logoos/EP_banner_DH20194.png" alt="DH2019 Utrecht University, The Netherlands" width="100%"/>
			<hr/>
			<br/>
			<div class="stdheader autogenerated">
				<h1 class="maintitle">A deep learning approach to Cadastral Computing</h1>
			</div>
			<div class="stdfooter autogenerated">
				<address>Sofia Ares Oliveira (sofia.oliveiraares@epfl.ch), EPFL, Switzerland and Isabella di Lenardo (isabella.dilenardo@epfl.ch), EPFL, Switzerland and Bastien Tourenc (bastien.tourenc@epfl.ch), EPFL, Switzerland and Frederic Kaplan (frederic.kaplan@epfl.ch), EPFL, Switzerland</address>
			</div>
			<br/>
			<div class="dhconvalidator-xml-link"/>
			<!--TEI front-->
			<!--TEI body-->
			<div class="DH-Heading1" id="index.xml-body.1_div.1">
				<h2 class="DH-Heading1">
					<span class="headingNumber">1. </span>
					<span class="head">Introduction</span>
				</h2>
				<p style="text-align:left; ">Among all the diverse typologies of administrative systems, the fiscal-cadastral sources retracing the ownership of lands are undoubtedly the richest and, in a sense, the most coherent records. The need for efficient tax collection processes pushed different administrations and political regimes in the 18th century to develop scale-invariant coherent property tracing system. These systems were progressively generalised at the turn of the 19th century with the abolition of privileges for certain classes of citizens and the establishment of republican administrations for managing cities and countries (Kain and Baigent 1993). The cadastre, by introducing a constant collection of taxes calculated on a fixed percentage, defines a new conception of the city and of the urban space. It marks the transition from the Ancient Regimes to the Modern State. The introduction of a constant, proportional and impartial tax determined a new conception of the city, adapted to statistical computations. In some sense, for the first time, the cadastre transforms the city into a computational object. We use the neologism “cadastral computing” to refer to the operations performed on such primary sources. This article presents a generic approach for processing automatically the information contained in the Napoleonic cadastres. The cadastres established during the first years of the 19th century cover a large part of Europe. For many cities they give one of the first geometrical surveys, linking precise parcels with identification numbers. These identification numbers point to register lines with the names of the parcel’s owners (Fig. 1). As the Napoleonic cadastres include millions of parcels, it therefore offers a detailed snapshot of large part of Europe’s population at the beginning of the 19th century (Clergeot 2007).</p>
				<div class="figure">
					<p style="text-align:left; ">
						<img class="inline" src="Pictures/93438d4ac1179064e4148b4cac01a528.png" alt="" style=" width:2.942266666666667cm; height:4.2cm;"/>
						<img class="inline" src="Pictures/dc5fd0c5fa4cc81727d256afde1f9a0c.jpg" alt="" style=" width:12.76933611111111cm; height:4.2cm;"/>
					</p>
					<p class="Image Caption">Figure 1. Identification numbers in parcels and in the register</p>
				</div>
				<p style="text-align:left; ">To develop a generic approach adapted to the processing of these administrative documents, one needs to solve two difficult challenges: (1) developing algorithms capable of robustly segmenting maps into parcels and administrative tables into cells (2) developing solutions for transcribing handwritten text containing people or places mentions and identification numbers. Until recently, these two problems were considered much beyond the state-of-the-art. The results of this article are based on the important progress recently made on both issues, using deep learning architectures. In 2017, an initial study on cadastre extraction showed promising results in parcel extraction and identifier recognition. However, it was entirely designed as an ad hoc pipeline fine-tuned for a particular cadastre (Ares Oliveira, Lenardo, and Kaplan 2017). A year later, a generic deep-learning segmentation engine, relying on a convolutional neural network (Ares Oliveira, Seguin, and Kaplan 2018) demonstrated that it was possible to design a generic architecture to segment many typologies of documents. In this article we use the genericity of this approach to develop the first fully automatic pipeline to transform the Napoleonic Cadastres into an information system.</p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.2">
				<h2 class="DH-Heading1">
					<span class="headingNumber">2. </span>
					<span class="head">Method</span>
				</h2>
				<p style="text-align:left; ">The automatic processing of the cadastre maps aims at extracting the parcels as geometrical shapes and also at transcribing the parcel’s identification numbers. It is composed of three main steps:</p>
				<p style="text-align:left; ">1. Training of the deep neural network on manually annotated data</p>
				<p style="text-align:left; ">2. Segmentation of the maps into meaningful regions and objects </p>
				<p style="text-align:left; ">3. Transcription of the identification numbers </p>
				<p style="text-align:left; ">Our segmentation network is a fully convolutional neural network inspired by the U-Net architecture (Ronneberger, Fischer, and Brox 2015). It uses a ResNet-50 pretrained network (He et al. 2016) as encoder, which speeds up the training, reduces the amount of training data needed and helps generalization. The full details of the architecture and open-source implementation can be found in (Ares Oliveira, Seguin, and Kaplan 2018). The network is trained to extract the parcel contours and text using annotated data from the Venetian cadastre (Fig. 2). The training data corresponds to roughly 1/3 of one map sheet among the 26 maps of the city of Venice (roughly 800 parcels).</p>
				<div class="figure">
					<img src="Pictures/a065d7188bec2cf3d2d293ca40f6a7c8.png" alt="" class="inline" style=" width:7.5cm; height:4.9006694444444445cm;"/>
					<p class="Image Caption">Figure 2. Sample of training data for cadastre maps segmentation. Parcels contour are in red, text is in green.</p>
				</div>
				<p style="text-align:left; ">The transcription network is a convolutional recurrent neural network (CRNN) (Shi, Bai, and Yao 2017) which produces a chain of characters when given an image segment containing text. The network is trained on samples of numbers from the Venetian archives and on numbers synthetically generated with MNIST digits (LeCun, Cortes, and Burges 1998) (Fig. 3).</p>
				<div class="figure">
					<img src="Pictures/c1b13e29e7fd80028b355d959f40e208.png" alt="" class="inline" style=" width:10.466255555555556cm; height:2.8cm;"/>
					<p class="Image Caption">Figure 3. Example of training data for the transcription system. Left: synthetically generated numbers; right: numbers from the Venetian archives.</p>
				</div>
				<p style="text-align:left; ">The segmentation model obtained after the training is able to predict the parcel contours and text region at pixel level (Fig. 4). Watershed by flooding algorithm (Beucher 1979) is applied on parcel contours predictions, which allows the extraction of parcel objects as polygonal shapes. Text regions are cropped, horizontally aligned and converted into grayscale image segments for further processing by the transcription system.</p>
				<div class="figure">
					<img src="Pictures/3725ac5eefec5763299482ccb9b49b96.png" alt="" class="inline" style=" width:16.14593888888889cm; height:4.8cm;"/>
					<p class="Image Caption">Figure 4. Output of the segmentation network (overlay in purple). Left: text extraction; right: contour extraction.</p>
				</div>
				<p style="text-align:left; ">The image segments containing text are fed to the transcription network, which outputs a prediction of a number, i.e. a chain of digits. Each transcription is then linked to its corresponding parcel. The contours of the parcels (whether they contain an identifier number or not) are saved as polygonal shapes and are exported into JSON format. In our case, since the images have previously been georeferenced, the coordinates are exported as geographical coordinates and can therefore directly be imported in any geographic information system. </p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.3">
				<h2 class="DH-Heading1">
					<span class="headingNumber">3. </span>
					<span class="head">Results</span>
				</h2>
				<p style="text-align:left; ">Two evaluations are performed in order to assess the performances of the system: the geographical accuracy of the extracted parcels and the transcription of the identification numbers.</p>
				<div class="figure">
					<img src="Pictures/c55e0a586addae05d8af01f7235f4663.png" alt="" class="inline" style=" width:13.210047222222222cm; height:8cm;"/>
					<p class="Image Caption">Figure 5. Visualization of the results of the automatic extraction of parcels. The red rectangle indicates the parcels used as training data for the segmentation network.</p>
				</div>
				<div class="DH-Heading2" id="index.xml-body.1_div.3_div.1">
					<h3 class="DH-Heading2">
						<span class="headingNumber">3.1. </span>
						<span class="head">Geometrical evaluation</span>
					</h3>
					<p style="text-align:left; ">The number of geometrical shapes extracted and manually annotated are listed in Tab. 1. After a filtering step, which keeps only shapes which area range from 2 m 
              <sup>2</sup>
          
           to 15000 m 
              <sup>2</sup>
          
          , the total number of extracted parcels is 28711, among which 18138 contain a transcription.
        </p>
					<div class="table">
						<table class="rules" style="border-collapse:collapse;border-spacing:0;">
							<caption>Table 1. Total number of geometries in the automatic extraction and manual annotation. The first three rows relate to automatically extracted parcels, the two last rows show the statistics for manually annotated parcels.</caption>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">Geometries</td>
								<td style="border: 1px solid black; padding: 2px;">Number</td>
							</tr>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">Geometries extracted automatically</td>
								<td style="border: 1px solid black; padding: 2px;">31 342</td>
							</tr>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">Geometries remaining after filtering</td>
								<td style="border: 1px solid black; padding: 2px;">28 711</td>
							</tr>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">---- with ID number</td>
								<td style="border: 1px solid black; padding: 2px;">18 138</td>
							</tr>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">Manually annotated geometries</td>
								<td style="border: 1px solid black; padding: 2px;">16 946</td>
							</tr>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">---- with ID number</td>
								<td style="border: 1px solid black; padding: 2px;">15 634</td>
							</tr>
						</table>
					</div>
					<p style="text-align:left; ">The quality of the parcel’s extraction is evaluated by measuring the intersection over union (IoU) between the geometries produced automatically and almost 17000 manually annotated shapes. Precision and recall with three different IoU thresholds 0.5 (acceptable), 0.7 (good), 0.9 (excellent) are reported in Tab. 2. The recall value shows that a large majority of parcels are extracted (85% in the most strict case). The low precision value is mainly due to the incorrect extraction of streets, squares, canals, etc. that are currently not filtered out (example in Fig. 6).</p>
					<div class="figure">
						<img src="Pictures/8ec8f2747a199fc1114aaa3e8e269973.png" alt="" class="inline" style=" width:8.159494444444444cm; height:6cm;"/>
						<p class="Image Caption">Figure 6. Example of false extraction of streets and canals (in blue)</p>
					</div>
					<div class="table">
						<table class="rules" style="border-collapse:collapse;border-spacing:0;">
							<caption>Table 2. Evaluation of the geometrical shape extraction with different Intersection over Union (IoU) thresholds.</caption>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">IoU</td>
								<td style="border: 1px solid black; padding: 2px;">Correct parcels</td>
								<td style="border: 1px solid black; padding: 2px;">Precision</td>
								<td style="border: 1px solid black; padding: 2px;">Recall</td>
							</tr>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">t=0.5</td>
								<td style="border: 1px solid black; padding: 2px;">15 999</td>
								<td style="border: 1px solid black; padding: 2px;">0.557</td>
								<td style="border: 1px solid black; padding: 2px;">0.944</td>
							</tr>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">t=0.7</td>
								<td style="border: 1px solid black; padding: 2px;">15 292</td>
								<td style="border: 1px solid black; padding: 2px;">0.533</td>
								<td style="border: 1px solid black; padding: 2px;">0.902</td>
							</tr>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">t=0.8</td>
								<td style="border: 1px solid black; padding: 2px;">14 440</td>
								<td style="border: 1px solid black; padding: 2px;">0.503</td>
								<td style="border: 1px solid black; padding: 2px;">0.852</td>
							</tr>
						</table>
					</div>
				</div>
				<div class="DH-Heading2" id="index.xml-body.1_div.3_div.2">
					<h3 class="DH-Heading2">
						<span class="headingNumber">3.2. </span>
						<span class="head">Transcription evaluation</span>
					</h3>
					<p style="text-align:left; ">We assess the performance of the transcription of parcel’s identifier numbers by computing the number of correct predictions and report the precision and recall values in Tab. 3. The current method assumes that the identifiers are located within the parcel, thus, identifiers partially or completely outside the geometrical shape are not correctly transcribed (Fig. 7), resulting in a lower recall.</p>
					<div class="figure">
						<img src="Pictures/71130d34d5bc0e7ae1355c6c1e259264.png" alt="" class="inline" style=" width:9.090180555555555cm; height:4.5cm;"/>
						<p class="Image Caption">Figure 7. Examples of identifiers numbers outside or partially outside the parcel.</p>
					</div>
					<p style="text-align:left; ">In order to increase the precision value and since we can assume that spatially close parcels will have numerically close identifiers, we tried to discard false predictions by determining if a transcription was ‘plausible‘ or not, using information from its spatial neighbourhood. Thus, a transcription is considered as an outlier if the (numerical) difference between the predicted number and the median of its 5 neighbouring transcriptions is greater than 10. This results in a significant increase in precision (up to 93%), but at the expense of a decrease in recall.</p>
					<div class="table">
						<table class="rules" style="border-collapse:collapse;border-spacing:0;">
							<caption>Table 3. Evaluation of the transcriptions of parcel’s identifiers numbers</caption>
							<tr>
								<td style="border: 1px solid black; padding: 2px;"/>
								<td style="border: 1px solid black; padding: 2px;">Correct transcriptions</td>
								<td style="border: 1px solid black; padding: 2px;">Precision</td>
								<td style="border: 1px solid black; padding: 2px;">Recall</td>
							</tr>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">Transcriptions</td>
								<td style="border: 1px solid black; padding: 2px;">11101</td>
								<td style="border: 1px solid black; padding: 2px;">0.612</td>
								<td style="border: 1px solid black; padding: 2px;">0.710</td>
							</tr>
							<tr>
								<td style="border: 1px solid black; padding: 2px;">Transcriptions after outlier detection</td>
								<td style="border: 1px solid black; padding: 2px;">8070</td>
								<td style="border: 1px solid black; padding: 2px;">0.927</td>
								<td style="border: 1px solid black; padding: 2px;">0.516</td>
							</tr>
						</table>
					</div>
				</div>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.4">
				<h2 class="DH-Heading1">
					<span class="headingNumber">4. </span>
					<span class="head">Perspectives</span>
				</h2>
				<p style="text-align:left; ">This initial study demonstrates on a particular case that 90% of the urban geometrical structure and more than 50% of a city population can be automatically remapped with high precision using only generic pipelines. Even if these numbers need to be confirmed on the basis of other case studies, the genericity of the methods used makes us optimistic about the possibility of conducting a large-scale study in the coming years. Such datasets call for a confrontation with the large number of historical hypotheses that have been formulated on the urban society at the beginning of the 19th century based on much smaller sets of evidence. Thanks to the standardisation processes of the Napoleonic administration, we hope in the coming months to extend this systematic processing beyond Venice to a large part of Europe.</p>
			</div>
			<!--TEI back-->
			<div class="bibliogr" id="index.xml-back.1_div.1">
				<h2>
					<span class="headingNumber">Appendix A </span>
				</h2>
				<div class="listhead">Bibliography</div>
				<ol class="listBibl">
					<li id="index.xml-bibl-w2350992aab3b3b1b1b3">
						<div class="First Paragraph">
							<span style="font-weight:bold">Ares Oliveira, Sofia, Isabella di Lenardo, and Frederic Kaplan</span>
            
            . (2017). Machine Vision Algorithms on Cadaster Plans. In 
                <span style="font-style:italic">Premiere Annual Conference of the International Alliance of Digital Humanities Organizations (Dh 2017)</span>
            
            .
          </div>
					</li>
					<li id="index.xml-bibl-w2350992aab3b3b1b1b5">
						<div class="biblfree">
							<span style="font-weight:bold">Ares Oliveira, Sofia, Benoit Seguin, and Frederic Kaplan</span>
            
            . (2018). DhSegment: A Generic Deep-Learning Approach for Document Segmentation. In 
                <span style="font-style:italic">Proceedings of 16th International Conference on Frontiers in Handwriting Recognition (Icfhr-2018)</span>
            
            .
          </div>
					</li>
					<li id="index.xml-bibl-w2350992aab3b3b1b1b7">
						<div class="biblfree">
							<span style="font-weight:bold">Beucher, S</span>
            
            . (1979). Use of Watersheds in Contour Detection. 
                <span style="font-style:italic">Proceedings of the International Workshop on Image Processing</span>
            
            . CCETT. 
                <a class="link_ref" href="https://ci.nii.ac.jp/naid/10008961959/en/">https://ci.nii.ac.jp/naid/10008961959/en/</a>
            
            .
          </div>
					</li>
					<li id="index.xml-bibl-w2350992aab3b3b1b1b9">
						<div class="biblfree">
							<span style="font-weight:bold">Clergeot, Pierre</span>
            
             (coord.). (2007). 
                <span style="font-style:italic">Cent Millions de Parcelles En France : 1807, Un Cadastre Pour L’Empire</span>
            
            . Éditions Publi-Topex.
          </div>
					</li>
					<li id="index.xml-bibl-w2350992aab3b3b1b1c11">
						<div class="biblfree">
							<span style="font-weight:bold">He, Kaiming, Xiangyu Zhang, Shaoqing Ren, and Jian Sun</span>
            
            . (2016). Deep Residual Learning for Image Recognition. In 
                <span style="font-style:italic">Proceedings of the Ieee Conference on Computer Vision and Pattern Recognition</span>
            
            , 770–78.
          </div>
					</li>
					<li id="index.xml-bibl-w2350992aab3b3b1b1c13">
						<div class="biblfree">
							<span style="font-weight:bold">Kain, R. J. P., and Elizabeth Baigent</span>
            
            . (1993). 
                <span style="font-style:italic">Cadastral Map in the Service of the State: History of Property Mapping.</span>
            
             Univ. Chicago P.
          </div>
					</li>
					<li id="index.xml-bibl-w2350992aab3b3b1b1c15">
						<div class="biblfree">
							<span style="font-weight:bold">LeCun, Yann, Corinna Cortes, and Christopher JC Burges</span>
            
            . (1998). The Mnist Database of Handwritten Digits.
          </div>
					</li>
					<li id="index.xml-bibl-w2350992aab3b3b1b1c17">
						<div class="biblfree">
							<span style="font-weight:bold">Ronneberger, Olaf, Philipp Fischer, and Thomas Brox</span>
            
            . (2015). U-Net: Convolutional Networks for Biomedical Image Segmentation. In 
                <span style="font-style:italic">International Conference on Medical Image Computing and Computer-Assisted Intervention</span>
            
            , 234–41. Springer.
          </div>
					</li>
					<li id="index.xml-bibl-w2350992aab3b3b1b1c19">
						<div class="biblfree">
							<span style="font-weight:bold">Shi, Baoguang, Xiang Bai, and Cong Yao</span>
            
            . (2017). An End-to-End Trainable Neural Network for Image-Based Sequence Recognition and Its Application to Scene Text Recognition. 
                <span style="font-style:italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</span>
            
             39 (11). IEEE: 2298–2304.
          </div>
					</li>
				</ol>
			</div>
			<hr/>
		</div>
	</body>
</html>
