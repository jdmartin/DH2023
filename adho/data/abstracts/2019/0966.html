<?xml version="1.0"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
		<!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
		<title>Classification of Text-Types in German Novels </title>
		<meta name="author" content="Daniel Schlör , Christof Schöch and Andreas Hotho"/>
		<meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
		<meta name="DC.Title" content="Classification of Text-Types in German Novels"/>
		<meta name="DC.Type" content="Text"/>
		<meta name="DC.Format" content="text/html"/>
		<link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
		<link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
		<style>
 div.dh2019 { max-width:1000px; margin: auto;}
 body {
       font-family: verdana;
       font-size: 11px;
}
 p {
    font-family: verdana;
    font-size: 11px;
}
</style>
	</head>
	<body>
		<div class="dh2019">
			<img src="https://dev.clariah.nl/files/dh2019/logoos/EP_banner_DH20194.png" alt="DH2019 Utrecht University, The Netherlands" width="100%"/>
			<hr/>
			<br/>
			<div class="stdheader autogenerated">
				<h1 class="maintitle">
					<span class="titlem">Classification of Text-Types in German Novels</span>
					<span class="titlem"/>
				</h1>
			</div>
			<div class="stdfooter autogenerated">
				<address>Daniel Schlör (daniel.schloer@informatik.uni-wuerzburg.de), University of Wuerzburg, Germany und Christof Schöch (schoech@uni-trier.de), University of Trier, Germany und Andreas Hotho (hotho@informatik.uni-wuerzburg.de), University of Wuerzburg, Germany</address>
			</div>
			<br/>
			<div class="dhconvalidator-xml-link"/>
			<!--TEI front-->
			<!--TEI body-->
			<div class="DH-Heading" id="index.xml-body.1_div.1">
				<h2 class="DH-Heading">
					<span class="headingNumber">1. </span>
					<span class="head">Introduction</span>
				</h2>
				<p>When working with literary texts, a problem for linguists, literary scholars and for machine-based text understanding is the classification of text-types. The term “text-type” refers to a variety of different phenomena reaching from a superordinate view of genre (Chatman 1990) to functionally motivated text-types as aggregations of structural or linguistic features (Biber 1988, 1989). While the taxonomy, textual layer and functionality of different theories behind text-types may differ widely, a common concept behind these theories is the understanding of textual surface structures varying in their respective text-type (Fludernik 2000). The text-types “descriptive”, “narrative” and “argumentative” emerge very frequently in many theories (Werlich 1975, Adam 1985, Chatman 1990). Being able to automatically assign sentences to these text-types is therefore highly desirable when aiming to support quantitative literary studies. In this work we present our text-type dataset, a feature based machine-learning model and a deep-learning based model and show that both are able to classify text-types.</p>
			</div>
			<div class="DH-Heading" id="index.xml-body.1_div.2">
				<h2 class="DH-Heading">
					<span class="headingNumber">2. </span>
					<span class="head">
						<a id="id__c6qdizhuhxk2">
							<!--anchor-->
						</a>
          
          Annotation Scheme
        </span>
				</h2>
				<p>Functionalizing the existing theories to a respective abstraction of surface phenomena, we came to our annotation guidelines:</p>
				<ul>
					<li class="item">descriptive: the description of a physical object in its dimensions, parts, and/or properties </li>
					<li class="item">narrative: the representation of a chain of events, actions or activities in its temporal progress driven by persons or other “actors” </li>
					<li class="item">argumentative: the presentation, explanation and justification of an abstract idea in its logical context </li>
				</ul>
				<p>To consider possible shortcomings of these guidelines or the underlying model and to give the annotators an opportunity to indicate their uncertainty, we introduced additionally the label “unknown”. In our annotation tool (see figure 1), sentences were presented within a small contextual framing.</p>
				<p>
					<a id="id__slkynvhz2bgt">
						<!--anchor-->
					</a>
				</p>
				<div class="figure">
					<img src="Pictures/b380c6a6c1950fd48c95f348dd0c87f2.png" alt="" class="graphic" width="100%"/>
				</div>
				<p>Figure 1: Contextual frame for the sentence (bold) to be annotated in our annotation tool</p>
			</div>
			<div class="DH-Heading" id="index.xml-body.1_div.3">
				<h2 class="DH-Heading">
					<span class="headingNumber">3. </span>
					<span class="head">
						<a id="id__yj3llp8wliwk">
							<!--anchor-->
						</a>
          
          Dataset
        </span>
				</h2>
				<p>We chose a random subset of 30 novels of the DROC corpus (Krug et al. 2017) for our experiments. From each novel we extracted a continuous segment of about 1% of the length. Each of the 1773 sentence obtained in this way was annotated by 3 annotators in order to judge the complexity of the annotation task and to identify a subset of sentences annotated with highly reliable text-type labels. Especially the argumentative text-type seemed to be difficult to annotate since the annotators often disagreed or showed uncertainty on the text-type e.g. for exclamations or other speech acts.</p>
				<p>When demanding full agreement among the annotators, the number of instances is reduced from 1773 to 830 sentences denoted as D 
            <span>S</span>
        
         (218 descriptive, 352 narrative, 260 argumentative). A majority vote (i.e. the consent of at least two of three annotators) leads to 1503 labeled instances denoted as D 
            <span>M</span>
        
         (366 descriptive, 540 narrative, 597 argumentative).
      </p>
			</div>
			<div class="DH-Heading" id="index.xml-body.1_div.4">
				<h2 class="DH-Heading">
					<span class="headingNumber">4. </span>
					<span class="head">
						<a id="id__gtqtpbyskr8g">
							<!--anchor-->
						</a>
          
          Experimental Setup
        </span>
				</h2>
				<div class="DH-Heading2" id="index.xml-body.1_div.4_div.1">
					<h3 class="DH-Heading2">
						<span class="headingNumber">4.1. </span>
						<span class="head">
							<a id="id__b0e92rfja25g">
								<!--anchor-->
							</a>
            
            Feature Construction
          </span>
					</h3>
					<p>For the task of classifying text-types, we modeled several features targeting different surface levels:</p>
					<p>
						<span style="font-weight:bold">Bag-of-Words</span>
          
          . As a baseline, we computed a simple count-based feature vector, representing how often which words occur per instance. 
              <br/>
						<span style="font-weight:bold">Indicator-Words. </span>
          
          Especially the 
              <span style="font-style:italic">argumentative</span>
          
           text-type has frequent discourse-related indicator words. We used discourse particles, modal particles, interjections and punctuation marks. 
              <br/>
						<span style="font-weight:bold">Word-Vectors.</span>
          
           In contrast to sparse bag-of-words vectors, dense word-vectors like Word2Vec (Mikolov et al. 2013) comprise semantic information. We used FastText (Mikolov et al. 2017) since the character-based model is able to model compound words implicitly, which are very common in German. After unsupervised training of 100 dimensional 
              <sup/>
						<span id="ftn1_return">
							<a class="notelink" title="Using 100 dimensions proved suitable in a initial experiment." href="#ftn1">
								<sup>1</sup>
							</a>
						</span>
						<sup/>
          
           word-vectors on the complete DROC corpus, a TSNE-based visualization of the vectors (Maaten &amp; Hinton 2008) revealed a noticeable cluster of words of the 
              <span style="font-style:italic">descriptive</span>
          
           text-type ranked via SD2-Zeta (Schöch et al. 2018) (see figure 2). Therefore, we modeled FastText based vector-semantics in two ways: averaging the word-vectors over all words within an instance and counting cluster-membership for words using a previously trained k-means (k=5) model.
        </p>
					<p>
						<span style="font-weight:bold">Germa-Net</span>
          
          . We used GermaNet (German WordNet) to generalize words in two ways: First, we followed each path towards to the most general hypernym and selected different hypernym levels as degrees of generalization. Second, we used GermaNets categorical structure for abstraction. Besides its taxonomic structure, GermaNet classifies words into 54 categories, e.g. the verb ‘sagen’ (engl. to say) belongs to the category ‘verb / communication’. We use these categories as generalizations for each word to reflect e.g. descriptions of places (‘adjective / place’) or people (‘adjective / body’).
        </p>
					<div class="figure">
						<img src="Pictures/db72c4b855be05499e5413185f7c0d24.png" alt="" class="graphic" width="100%"/>
					</div>
					<p>
						<br/>
          
          Figure 2: TSNE-Visualization of FastText word-vectors. Blue color indicates that a word is more prominent for the descriptive text-type. The indicativeness was judged opposing the descriptive and other text-types via SD2 Zeta. Other text-types show similar results.
        </p>
				</div>
				<div class="DH-Heading2" id="index.xml-body.1_div.4_div.2">
					<h3 class="DH-Heading2">
						<span class="headingNumber">4.2. </span>
						<span class="head">
							<a id="id__8fitqs3fa9mn">
								<!--anchor-->
							</a>
            
            Classification Task
          </span>
					</h3>
					<p>To examine the contribution of each feature, we conducted an extensive feature analysis using a Support Vector Machine (SVM) 
              <sup/>
						<span id="ftn2_return">
							<a class="notelink" title="Random Forest classifier achieved slightly worse to similar results." href="#ftn2">
								<sup>2</sup>
							</a>
						</span>
						<sup/>
          
           as a classifier and compared its performance to a deep-learning based Recurrent Neural Network (RNN) Model.
        </p>
					<p>The SVM was used with linear and RBF kernels, varying the hyperparameter C 
              <sup/>
						<span id="ftn3_return">
							<a class="notelink" title="C ∈{1,10,100,1000}" href="#ftn3">
								<sup>3</sup>
							</a>
						</span>
						<sup/>
          
          . Additionally we also evaluated the influence of the degree of generalization using GermaNet on the classification performance.
        </p>
					<p>For the RNN, we adopted the BiGRU model from (Song et al. 2017) but introduced additional loss functions and model parameters as follows: We varied the number of GRU layers between 1 and 4 and the dimensions of the hidden layers between 100 and 400. We used the pretrained FastText model as initial embedding weights. </p>
					<p>We conducted a grid-search based parameter study for both classifiers to find the best model-parameter configuration. The model architecture is depicted in figure 3. </p>
					<div class="figure">
						<img src="Pictures/80793237b427a9ed43df7675e31af65a.png" alt="" class="graphic" width="100%"/>
					</div>
					<p>Figure 3: BiRNN Model. Number of GRU Layers were varied between one and four in a parameter-study. Categorical-cross-entropy as loss and softmax as activation achieved best results.</p>
					<p>Table 1: Precision, recall, f1-score and accuracy for the SVM classifier on a random hold-out dataset from D 
              <span>S</span>
          
           and D 
              <span>M</span>
					</p>
					<div class="figure">
						<img src="Pictures/ef3552fb6d9c3e493ef1415974dfbf71.png" alt="" class="graphic" width="100%"/>
					</div>
					<p/>
				</div>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.5">
				<h2 class="DH-Heading1">
					<span class="headingNumber">5. </span>
					<span class="head">
						<a id="id__bfp4q9c4b6vy">
							<!--anchor-->
						</a>
          
          Results
        </span>
				</h2>
				<p>We evaluate the models on sampled hold-out dataset fractions of 10% and report accuracy for both datasets, D 
            <span>S</span>
        
         and D 
            <span>M</span>
        
        . The majority baseline (always predicting the most frequent class) yields an accuracy of 0. 
            <span class="background-color(#ffffff)">457 for D</span>
					<span class="background-color(#ffffff)sub">M</span>
					<span class="background-color(#ffffff)">and 0.398 for D</span>
					<span class="background-color(#ffffff)sub">S</span>
					<span class="background-color(#ffffff)">.</span>
				</p>
				<p>The best performance of 0.864 mean 
            <sup/>
					<span id="ftn4_return">
						<a class="notelink" title="For 20 repetitions on different hold out-sets" href="#ftn4">
							<sup>4</sup>
						</a>
					</span>
					<sup/>
        
         accuracy ± 0.047 standard deviation for D 
            <span>s</span>
        
         resp. 0.776 ± 0.022 for D 
            <span>M</span>
        
         was achieved by the linear SVM classifier, C = 1, only using the average FastText word vectors as feature (see table 1 for a label-wise evaluation). This result supports our finding of rather distinct text-type word-vector clusters in our explorative analysis. However, we surprisingly find that additional features do not improve the result. The best feature combinations without averaged FastText vectors yield significantly 
            <sup/>
					<span id="ftn5_return">
						<a class="notelink" title="For 20 repetitions on different hold out-sets, α = 0.05 using Pitman’s permutation test as suggested by (Dror et al. 2018)" href="#ftn5">
							<sup>5</sup>
						</a>
					</span>
					<sup/>
        
         lower accuracies (0.813 resp. 0.735) and use the FastText cluster features. The best features without any FastText use bag-of-words and part-of-speech features for D 
            <span>M</span>
        
         (0.696) and additionally GermaNet hypernym and category features for D 
            <span>S</span>
        
         (0.751).
      </p>
				<p>The generalization-depth study aimed at finding the optimal degree of lexical generalization between the word itself and a very abstract and non-indicative root-hypernym. We therefore followed the hypernym path from each word to each root-hypernym and selected the highest and the lowest three hypernym-levels in a classification setup only using this feature. Our results indicate that the second hypernym (i.e. the hypernym of the hypernym of the word) is the most promising level of abstraction for our task. However, we are aware of the problem that hypernym relations for different words might each represent different degrees of abstraction, depending on the level of detail at which the taxonomy is modeled.</p>
				<p>The RNN model achieved significantly 
            <sup/>
					<span id="ftn6_return">
						<a class="notelink" title="For 10 repetitions on different hold out-sets, α = 0.05 using Pitman’s permutation test." href="#ftn6">
							<sup>6</sup>
						</a>
					</span>
					<sup/>
        
         lower accuracies for all model variations in comparison to the SVM. We believe that this is mainly a problem of too few training data since in theory, the RNN should be able to model the best performing feature, the averaged FastText vectors. In contrast to (Song et al. 2017), our best performing model used categorical-cross-entropy as loss function and one GRU layer with a dimensionality of 400 on both datasets reaching a mean 
            <sup/>
					<span id="ftn7_return">
						<a class="notelink" title="For 10 repetitions on different hold out-sets." href="#ftn7">
							<sup>7</sup>
						</a>
					</span>
					<sup/>
        
         accuracy of 0.801 ± 0.049 standard deviation for D 
            <span>S</span>
        
         and 0.702 ± 0.029 for D 
            <span>M</span>
        
        .
      </p>
				<p>All detailed results, including the results for our feature study are also available on GitHub 
            <sup/>
					<span id="ftn8_return">
						<a class="notelink" title="https://github.com/cligs/projects2019/DH_TextTypes" href="#ftn8">
							<sup>8</sup>
						</a>
					</span>
					<sup/>
        
        .
      </p>
			</div>
			<div class="DH-Heading" id="index.xml-body.1_div.6">
				<h2 class="DH-Heading">
					<span class="headingNumber">6. </span>
					<span class="head">
						<a id="id__z39qsvm08w9a">
							<!--anchor-->
						</a>
          
          Discussion and Future Work
        </span>
				</h2>
				<p>Our results show that an SVM as well as a deep-learning approach are able to classify text-types with an accuracy far beyond the baseline. To some extent, handcrafted features are able to compensate the small amount of training data for the D 
            <span>S</span>
        
         dataset with an SVM and outperformed the best deep-learning based model. Since the performance of deep-learning based models heavily relies on a sufficient amount of training data, this outcome isn’t very surprising and might be revised if more data becomes available. In comparison, the feature driven linear SVM classifier might also have an advantage when it comes to interpretability: The coefficient-weights of an SVM classifier can be interpreted as a whitebox model (Zehe et al. 2017) and reveal interpretable insights into the decision process, whereas the decisions made by a neural network cannot easily be inspected, which is crucial for theory construction and deconstruction in the (digital) humanities.
      </p>
				<p>For future work, we plan to examine in detail why the handcrafted features such as indicator-words or WordNet abstractions don’t seem to be as useful as expected. We also plan to incorporate data augmentation methods and finally do a consolidating annotation run to have a bigger and cleaner text-type dataset.</p>
			</div>
			<!--TEI back-->
			<div class="bibliogr" id="index.xml-back.1_div.1">
				<h2>
					<span class="headingNumber">Appendix A </span>
				</h2>
				<div class="listhead">Bibliography</div>
				<ol class="listBibl">
					<li id="index.xml-bibl-w2664484aab3b3b1b1b3">
						<div class="biblfree">Adam, Jean-Michel, (1985). “Quels types de textes?” Le français dans le Monde 192, 39-43.</div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1b5">
						<div class="biblfree">Biber, Douglas, (1988). Variation Across Speech and Writing. Cambridge University Press, Cambridge. 
                <br/>
            
            Biber, Douglas, (1989). A typology of English texts. Linguistics 27, 3–43. 
                <br/>
            
            Chatman, S. (1990). Coming to Terms: The Rhetoric of Narrative in Fiction and Film. Ithaca, NY: Cornell University Press.
          </div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1b7">
						<div class="biblfree">Dror, R., Baumer, G., Shlomov, S., &amp; Reichart, R. (2018). The hitchhiker’s guide to testing statistical significance in natural language processing. In 
                <span style="font-style:italic">Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>
            
             (Vol. 1, pp. 1383-1392).
          </div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1b9">
						<div class="biblfree">Fludernik, Monika. (2000). “Genres, text types, or discourse modes? Narrative modalities and generic categorization.” 
                <span style="font-style:italic">Style</span>
            
             34.2, 274-292.
          </div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1c11">
						<div class="biblfree">Krug M., Puppe F., Reger I., Weimer L., Macharowsky L., Feldhaus S. &amp; Jannidis F. (2018) Description of a Corpus of Character References in German Novels - DROC [Deutsches ROman Corpus]. DARIAH-DE Working Papers Nr. 27. Göttingen: DARIAH-DE</div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1c13">
						<div class="biblfree">Maaten, L. V. D., &amp; Hinton, G. (2008). Visualizing data using t-SNE. 
                <span style="font-style:italic">Journal of machine learning research</span>
            
            , 
                <span style="font-style:italic">9</span>
            
            (Nov), 2579-2605.
          </div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1c15">
						<div class="biblfree">Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., &amp; Dean, J. (2013). Distributed representations of words and phrases and their compositionality. In 
                <span style="font-style:italic">Advances in neural information processing systems</span>
            
             (pp. 3111-3119).
          </div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1c17">
						<div class="biblfree">Mikolov, T., Grave, E., Bojanowski, P., Puhrsch, C., &amp; Joulin, A. (2017). Advances in pre-training distributed wordrepresentations. 
                <span style="font-style:italic">arXiv preprint arXiv:1712.09405</span>
            
            .
          </div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1c19">
						<div class="biblfree">Schöch C., Schlör D., Zehe A., Gebhard H., Becker M &amp;, Hotho A. (2018). Burrows' Zeta: Exploring and Evaluating Variants and Parameters. DH 2018: 274-277.</div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1c21">
						<div class="biblfree">Song, W., Wang, D., Fu, R., Liu, L., Liu, T., &amp; Hu, G. (2017). Discourse mode identification in essays. In 
                <span style="font-style:italic">Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</span>
            
             (Vol. 1, pp. 112-122).
          </div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1c23">
						<div class="biblfree">Werlich, Egon. (1975). Typologie der Texte: Entwurf eines textlinguistischen Modells zur</div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1c25">
						<div class="biblfree">Grundlegung einer Textgrammatik. Heidelberg: Quelle &amp; Meyer.</div>
					</li>
					<li id="index.xml-bibl-w2664484aab3b3b1b1c27">
						<div class="biblfree">
							<a id="id__GoBack2">
								<!--anchor-->
							</a>
            
            Zehe A., Schlör D., Henny-Krahmer U., Becker M. &amp; Hotho A. (2018). A White-Box Model for Detecting Author Nationality by Linguistic Differences in Spanish Novels. DH 2018: 519-521
          </div>
					</li>
				</ol>
			</div>
			<!--Notes in [TEI]-->
			<div class="notes">
				<div class="noteHeading">Notes</div>
				<div class="note" id="ftn1">
					<span class="noteLabel">1. </span>
					<div class="noteBody">Using 100 dimensions proved suitable in a initial experiment.</div>
				</div>
				<div class="note" id="ftn2">
					<span class="noteLabel">2. </span>
					<div class="noteBody">Random Forest classifier achieved slightly worse to similar results.</div>
				</div>
				<div class="note" id="ftn3">
					<span class="noteLabel">3. </span>
					<div class="noteBody">C ∈{1,10,100,1000}</div>
				</div>
				<div class="note" id="ftn4">
					<span class="noteLabel">4. </span>
					<div class="noteBody">For 20 repetitions on different hold out-sets</div>
				</div>
				<div class="note" id="ftn5">
					<span class="noteLabel">5. </span>
					<div class="noteBody">For 20 repetitions on different hold out-sets, α = 0.05 using Pitman’s permutation test as suggested by (Dror et al. 2018)</div>
				</div>
				<div class="note" id="ftn6">
					<span class="noteLabel">6. </span>
					<div class="noteBody">For 10 repetitions on different hold out-sets, α = 0.05 using Pitman’s permutation test.</div>
				</div>
				<div class="note" id="ftn7">
					<span class="noteLabel">7. </span>
					<div class="noteBody">For 10 repetitions on different hold out-sets.</div>
				</div>
				<div class="note" id="ftn8">
					<span class="noteLabel">8. </span>
					<div class="noteBody">https://github.com/cligs/projects2019/DH_TextTypes</div>
				</div>
			</div>
			<hr/>
		</div>
	</body>
</html>
