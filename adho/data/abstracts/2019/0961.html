<?xml version="1.0"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
		<!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
		<title>Bootstrapping Project-specific Spell-checkers </title>
		<meta name="author" content="C. M. Sperberg-McQueen and Claus Huitfeldt"/>
		<meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
		<meta name="DC.Title" content="Bootstrapping Project-specific Spell-checkers"/>
		<meta name="DC.Type" content="Text"/>
		<meta name="DC.Format" content="text/html"/>
		<link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
		<link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
		<style>
 div.dh2019 { max-width:1000px; margin: auto;}
 body {
       font-family: verdana;
       font-size: 11px;
}
 p {
    font-family: verdana;
    font-size: 11px;
}
</style>
	</head>
	<body>
		<div class="dh2019">
			<img src="https://dev.clariah.nl/files/dh2019/logoos/EP_banner_DH20194.png" alt="DH2019 Utrecht University, The Netherlands" width="100%"/>
			<hr/>
			<br/>
			<div class="stdheader autogenerated">
				<h1 class="maintitle">
					<span class="titlem">Bootstrapping Project-specific Spell-checkers</span>
					<span class="titlem"/>
				</h1>
			</div>
			<div class="stdfooter autogenerated">
				<address>C. M. Sperberg-McQueen (cmsmcq@acm.org), Black Mesa Technologies LLC, United States of America and Claus Huitfeldt (Claus.Huitfeldt@uib.no), Universitetet i Bergen</address>
			</div>
			<br/>
			<div class="dhconvalidator-xml-link"/>
			<!--TEI front-->
			<!--TEI body-->
			<p>Spell-checking software is well established in consumer applications but often unexploited by data-creation projects in the digital humanities. We argue that spell-checking provides a relatively straightforward way to find (some) transcription errors even in texts written in idiosyncratic or inconstant spelling. </p>
			<div class="DH-Heading1" id="index.xml-body.1_div.1">
				<h2 class="DH-Heading1">
					<span class="headingNumber">1. </span>
					<span class="head">Working hypotheses</span>
				</h2>
				<p>We believe that spell checking is feasible, useful, and underused in DH projects.</p>
				<p>More specifically:</p>
				<ul>
					<li class="item">Fewer than half of DH projects transcribing existing materials use spell-checking technology.</li>
					<li class="item">Standard word-in-isolation spell checking can find transcription errors.</li>
					<li class="item">Project-specific spelling dictionaries can do better than off-the-shelf dictionaries for 
              <ul>
							<li class="item">writing by idiosyncratic or inconstant spellers</li>
							<li class="item">older language forms no longer supported in off-the-shelf dictionaries</li>
							<li class="item">non-standard and minority languages which lack off-the-shelf dictionaries</li>
						</ul>
					</li>
					<li class="item">Project-specific filters may be necessary to create a checkable alpha text ([Huitfeldt 2006]) but are feasible.</li>
				</ul>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.2">
				<h2 class="DH-Heading1">
					<span class="headingNumber">2. </span>
					<span class="head">Modeling spell-checking, modeling languages</span>
				</h2>
				<p>In conventional word-in-isolation spell-checking ([Earnest 2011], [Damerau 1964], [McIlroy 1982], [Bentley 1986], [Peterson 1980], [Kuenning 2018], [Atkinson 2017], [Németh 2018]), the language model is trivial: all acceptable forms are equiprobable, a form is acceptable if and only if listed in the dictionary, unknown forms have probability zero, and any token with probability zero is a probable error. To find alternative spellings, a Levenshtein distance of one ([Norvig 2007]) or more ([Garbe 2012], [Garbe 2015]) is sometimes used. A combination of phonetic encoding and Levenshtein distance can sometimes be helpful ([Atkinson 2017]).</p>
				<p>Recent work on spelling correction (e.g. [Choudhury et al. 2018], [Dashti et al. 2018]) uses more elaborate models to detect ‘real-word’ errors (e.g. “be” for “he”).</p>
				<p>In this paper, however, we assume the simple model of text as a sequence of equiprobable known forms.</p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.3">
				<h2 class="DH-Heading1">
					<span class="headingNumber">3. </span>
					<span class="head">Challenges in using spell-checking</span>
				</h2>
				<p>For spell-checking in DH projects, some complications arise.</p>
				<ul>
					<li class="item">Transcribers normally seek to reproduce the spelling of the exemplar, not to correct it. When standard spelling dictionaries are used to check material which consistently violates orthographic norms (idiosyncratic spelling), they will erroneously flag some correctly transcribed misspellings and miss unconscious corrections by the transcriber.</li>
					<li class="item">Off-the-shelf dictionaries reflect current norms for widely spoken languages. Older language varieties and under-resourced languages often lack dictionaries.</li>
					<li class="item">The language transcribed may have no standardized orthography; spelling may vary by scribe or line-by-line (inconstant spelling).</li>
					<li class="item">XML documents may contain material not to be spell-checked (markup, project-internal comments, etc.), or material in different languages or varieties (e.g. 21st-century English in the header and 17th-century English in the body).</li>
				</ul>
				<p>We believe these complications can be addressed.</p>
				<p>For idiosyncratic spelling, the solution is to use a project-specific dictionary, not a standard dictionary, so that correctly transcribed misspellings will be accepted and inadvertent corrections flagged.</p>
				<p>Inconstant spelling makes spell-checkers miss transcription errors that substitute one accepted form for another. But spell-checking can still catch other errors. (Similarly, an English spelling dictionary with both British and American spellings won't catch "colour" in American texts, but it will catch the typo "teh".)</p>
				<p>Producing project-specific dictionaries from scratch requires some work, but our experiments suggest that even modest effort can produce spelling dictionaries that will detect existing transcription errors without excessive noise.</p>
				<p>For dealing with XML, it's helpful to write filters to extract the desired word forms. Fortunately, this is normally straightforward.</p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.4">
				<h2 class="DH-Heading1">
					<span class="headingNumber">4. </span>
					<span class="head">A small pilot study</span>
				</h2>
				<p>Several practical questions arise:</p>
				<ul>
					<li class="item">How can project-specific dictionaries be constructed?</li>
					<li class="item">What should they contain (and exclude)?</li>
					<li class="item">How much work is involved? How big must the dictionary be: 
              <ul>
							<li class="item">to catch as many actual errors as possible?</li>
							<li class="item">not to flag correctly transcribed words erroneously?</li>
						</ul>
					</li>
					<li class="item">How much project data is necessary to obtain a dictionary of that size?</li>
				</ul>
				<p>We have explored these questions using material from the Wittgenstein Archives at the University of Bergen and from Liam Quin's digital version of Alexander Chalmers's General Biographical Dictionary ([Quin 2017]).</p>
				<ul>
					<li class="item">For each project, we selected test material: for Wittgenstein, two small texts taken from non-final versions of the corpus; for Chalmers, 10,000 words from volume 25.</li>
					<li class="item">For Wittgenstein, we checked the normalized-spelling text, identifying word forms which violate German orthographic norms. 
              <span id="ftn0_return">
							<a class="notelink" title="The Wittgenstein project defined standard orthography as that of Duden's Rechtschreibung, but admitted some idiosyncratic spellings consistently used …" href="#ftn0">
								<sup>i</sup>
							</a>
						</span>
					</li>
					<li class="item">For Chalmers, we proofread the sample against the page scans.</li>
					<li class="item">With programmatic filters we extracted an alpha text (a list of words for spell-checking).</li>
					<li class="item">We constructed dictionaries of various sizes by compiling lists of correct forms from different subsets of the project corpora. 
              <span id="ftn1_return">
							<a class="notelink" title="In principle, project-specific dictionaries should be built by proofreading texts one-by-one; to streamline the pilot project, we took the shortcut of…" href="#ftn1">
								<sup>ii</sup>
							</a>
						</span>
					</li>
					<li class="item">We checked the test samples against those dictionaries.</li>
					<li class="item">For each test, we counted the number of correct and incorrect tokens in the sample flagged or left unflagged by the spell checker.</li>
				</ul>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.5">
				<h2 class="DH-Heading1">
					<span class="headingNumber">5. </span>
					<span class="head">Results of the pilot study</span>
				</h2>
				<div class="DH-Heading2" id="index.xml-body.1_div.5_div.1">
					<h3 class="DH-Heading2">
						<span class="headingNumber">5.1. </span>
						<span class="head">Constructing project-specific dictionaries</span>
					</h3>
					<p>The simplest (not fastest) method is to start with an empty dictionary and spell-check texts from the project's corpus one by one. For each word flagged by the spell checker, either add it to the dictionary or correct it in the text. (More on this below.)</p>
					<p>With an empty dictionary, the spell-checker will at first flag every form in the text. To avoid the tedium of dealing with so many bad flags, it may be worthwhile to list the most frequent forms in whatever part of the corpus is available for consultation, check them manually, and seed the dictionary with them. For Wittgenstein, a dictionary of 1300 forms covers about 90% of the running tokens in the text, flagging only one token in ten.</p>
				</div>
				<div class="DH-Heading2" id="index.xml-body.1_div.5_div.2">
					<h3 class="DH-Heading2">
						<span class="headingNumber">5.2. </span>
						<span class="head">What to include and exclude</span>
					</h3>
					<p>Ideally, the dictionary should include all forms which actually occur correctly in the corpus and no forms which are transcription errors. This ideal is unattainable for two reasons. First, the same form may occur both as a correct transcription and as a mistranscription (real-word errors); it cannot be both included and excluded. Second, as the corpus grows, there will always be some correct forms not yet found in the dictionary, and thus always some erroneous flags.</p>
					<p>The optimal solution is to balance the relative inconvenience of undetected errors and false flags against the relative frequency with which each form is correct or mistranscribed. If undetected errors and bad flags have equal weight, then a form should be included in the dictionary if any occurrence is more likely correct than not. If we would rather see ten bad flags than miss one mistranscription, then a form should be included only if it is ten times more likely to be correct than incorrect. The project's preferences determine the threshold to be met.</p>
					<p>If spelling habits vary from document to document, it can be useful to make both a project-wide dictionary and document-specific dictionaries for texts with distinctive usage.</p>
					<p>When forms intentionally excluded from the dictionary do occur correctly transcribed, they can be marked with sic or similar markup and excluded from the alpha text, to avoid throwing bad flags for them.</p>
					<p>With these complications, the rule for forms flagged by the spell-checker becomes:</p>
					<ul>
						<li class="item">If the form is correctly transcribed and meets the project's correctness threshold, add it to the project dictionary.</li>
						<li class="item">If the form is correctly transcribed and meets the threshold in the current document but not elsewhere, then add it to the document-specific dictionary.</li>
						<li class="item">If the form is correctly transcribed but does not meet the threshold, then tag it with sic or the equivalent.</li>
						<li class="item">If the form is incorrectly transcribed, correct it.</li>
					</ul>
				</div>
				<div class="DH-Heading2" id="index.xml-body.1_div.5_div.3">
					<h3 class="DH-Heading2">
						<span class="headingNumber">5.3. </span>
						<span class="head">Dictionary size</span>
					</h3>
					<p>Error detection does not require a big dictionary. Indeed, because of real-word errors, bigger dictionaries often find fewer actual errors than smaller dictionaries, as shown below for Chalmers.</p>
					<div class="figure">
						<img src="Pictures/63fffc2c03a8fb329c738d5e33602d4a.png" alt="Plot of dictionary size (x axis) and number of correct error reports (y axis)" class="graphic" width="100%"/>
					</div>
					<p>Small dictionaries, however, throw too many bad flags. Fortunately, the number of bad flags falls dramatically as dictionary size rises, as shown below for Wittgenstein (red, two samples) and Chalmers (blue).</p>
					<div class="figure">
						<img src="Pictures/b3a987ff9117798391b1a0f1b2bd4fa2.png" alt="Plot of dictionary size (x axis) and number of erroneous flags (y axis)" class="graphic" width="100%"/>
					</div>
					<p>Whether spell-checking feels useful or pointless depends (we think) on its signal:noise ratio; in our data dictionaries of about 15,000 forms reach a (bearable?) ratio of 1:10 (ten erroneous flags for each detected error).</p>
					<div class="figure">
						<img src="Pictures/ff745ba025e45a4c44b54638aa6aac98.png" alt="Plot of dictionary size (x axis) and signal/noise ratio (y axis)" class="graphic" width="100%"/>
					</div>
					<p>How big a corpus must be processed to produce a dictionary of suitable size? It varies, but as the plots below show, something more than 200,000 tokens are needed for a dictionary of 15,000 forms.</p>
					<div class="figure">
						<img src="Pictures/617e51282c2a33e2edea5e6bdab1eccb.png" alt="Plot of corpus size (x axis) and dictonary size (y axis) [small corpora only]" class="graphic" width="100%"/>
					</div>
					<p/>
					<div class="figure">
						<img src="Pictures/83e0dbdbb731f6c4e1f67947d2616f5e.png" alt="Plot of corpus size (x axis) and dictonary size (y axis) [all corpora]" class="graphic" width="100%"/>
					</div>
				</div>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.6">
				<h2 class="DH-Heading1">
					<span class="headingNumber">6. </span>
					<span class="head">Conclusions and future work</span>
				</h2>
				<p>Spell checking can find transcription errors in real-world data, even though transcription errors are logically distinct from misspellings and even when the spelling is idiosyncratic or inconstant.</p>
				<p>Developing a project-specific dictionary takes little time and can be expected to improve the results of proofreading. Even very small project-specific dictionaries can be useful.</p>
				<p>Work remains to be done to extend the pilot study to more materials, to support interactive correction of texts, to improve on the XML support offered by existing spell-checkers, and to explore the application of more sophisticated models of text to support word-in-context spell-checking in lieu of word-in-isolation spell-checking.</p>
			</div>
			<!--TEI back-->
			<div class="bibliogr" id="index.xml-back.1_div.1">
				<h2>
					<span class="headingNumber">Appendix A </span>
				</h2>
				<div class="listhead">Bibliography</div>
				<ol class="listBibl">
					<li id="index.xml-bibl-w785782aab3b3b1b1b3">
						<div class="biblfree">[Atkinson 2017] Atkinson, Kevin. “GNU Aspell.” 
                <a class="link_ref" href="http://aspell.net/">http://aspell.net</a>
            
             (Last rev. 30 January 2017).
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1b5">
						<div class="biblfree">[Bentley 1986] Bentley, Jon. 1985. “A spelling checker”. In Programming Pearls.. Reading, Mass.: Addison-Wesley, 1986, pp. 139-150. Reprinted from Communications of the ACM May 1985.</div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1b7">
						<div class="biblfree">[Charniak 1993] Charniak, Eugene. 
                <span style="font-style:italic">Statistical Language Learning</span>
            
            . Cambridge, Mass.: MIT Press, 1993.
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1b9">
						<div class="biblfree">[Choudhury et al. 2018] Choudhury, Ranjan, Nabamita Deb, and Kishore Kashyap. “Context-Sensitive Spelling Checker for Assamese Language.” 2018. In 
                <span style="font-style:italic">Recent Developments in Machine Learning and Data Analytics</span>
            
            , ed. Jugal Kalita, Valentina Emilia Balas, Samarjeet Borah, Ratika Pradhan (= Advances in Intelligent Systems and Computing 740). New York, etc.: Springer, 2018, pp. 177-188.
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c11">
						<div class="biblfree">[Damerau 1964] Damerau, Fred J. 1964. “A technique for computer detection and correction of spelling errors”. 
                <span style="font-style:italic">Communications of the ACM</span>
            
             7.3 (March 1964): 171-176.
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c13">
						<div class="biblfree">[Dashti et al. 2018] Dashti, Seyed MohammedSadegh, Amid Khatibi Bardsiri, and Vahid Khatibi Bardsiri. “Correcting real-word spelling errors: A new hybrid approach.” 
                <span style="font-style:italic">Digital Scholarship in the Humanities</span>
            
             33.3 (2018): 488-499.
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c15">
						<div class="biblfree">
							<a id="id_earnest">
								<!--anchor-->
							</a>
            
            [Earnest 2011] Earnest, Les. “The three first spelling checkers”. Unpublished sketch, May 2011. On the Web at 
                <a class="link_ref" href="https://web.archive.org/web/20121022091418/http://www.stanford.edu/~learnest/spelling.pdf">https://web.archive.org​/web​/20121022091418​/brhttp:​/​/www.stanford.edu​/~learnest​/spelling.pdf</a>
            
            , archived from 
                <a class="link_ref" href="http://www.stanford.edu/~learnest/spelling.pdf">http://www.stanford.edu​/~learnest​/spelling.pdf</a>
            
            .
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c17">
						<div class="biblfree">
							<a id="id_garbe2012">
								<!--anchor-->
							</a>
            
            [Garbe 2012] Garbe, Wolf. 2012. “Fast 1000x Faster Spelling Correction algorithm.” Blog post originally posted at http://blog.faroo.de​/2012​/06​/07​/improved-edit-distance-based-spelling-correction/ and now at https://medium.com​/@wolfgarbe​/1000x-faster-spelling-correction-algorithm-2012-8701fcd87a5f
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c19">
						<div class="biblfree">
							<a id="id_garbe2015">
								<!--anchor-->
							</a>
            
            [Garbe 2015] Garbe, Wolf. 2015. “Fast approximate string matching with large edit distances in Big Data.” Blog post originally posted at 
                <a class="link_ptr" href="http://blog.faroo.de/2015/03/24/fast-approximate-string-matching-with-large-edit-distances/">
								<span>http://blog.faroo.de/2015/03/24/fast-approximate-string-matching-with-large-edit-distances/</span>
							</a>
            
             and now at 
                <a class="link_ptr" href="https://medium.com/@wolfgarbe/fast-approximate-string-matching-with-large-edit-distances-in-big-data-2015-9174a0968c0b">
								<span>https://medium.com/@wolfgarbe/fast-approximate-string-matching-with-large-edit-distances-in-big-data-2015-9174a0968c0b</span>
							</a>
						</div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c21">
						<div class="biblfree">[Huitfeldt 2006] Huitfeldt, Claus. 2006. “Philosophy Case Study.” In 
                <span style="font-style:italic">Electronic Textual Editing</span>
            
            , ed. Lou Burnard, Katherine O´Brien O´Keeffe, and John Unsworth. New York: MLA 2006, pp. 181-96.
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c23">
						<div class="biblfree">
							<a id="id_kuenning">
								<!--anchor-->
							</a>
            
            [Kuenning 2018] Kuenning, Geoff. “International ispell [v 3.4.00].” 
                <a class="link_ptr" href="https://www.cs.hmc.edu/~geoff/ispell.html">
								<span>https://www.cs.hmc.edu/~geoff/ispell.html</span>
							</a>
            
             (Last rev. 26 March 2018).
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c25">
						<div class="biblfree">[McIlroy 1982] McIlroy, Douglas. “Development of a spelling list.” 
                <span style="font-style:italic">IEEE Transactions on Communications</span>
            
             30.1 (January 1982): 91-99.
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c27">
						<div class="biblfree">
							<a id="id_nemeth">
								<!--anchor-->
							</a>
            
            [Németh 2018] Németh, László. 2018. “Hunspell.” 
                <a class="link_ref" href="http://hunspell.github.io/">http://hunspell.github.io</a>
            
             (Last rev. 6 July 2018).
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c29">
						<div class="biblfree">
							<a id="id_norvig">
								<!--anchor-->
							</a>
            
            [Norvig 2007] Norvig, Peter. “How to Write a Spelling Corrector.” Blog post Feb. 2007 (with periodic revisions to August 2016). 
                <a class="link_ptr" href="http://norvig.com/spell-correct.html">
								<span>http://norvig.com/spell-correct.html</span>
							</a>
						</div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c31">
						<div class="biblfree">[Peterson 1980] Peterson, James L. “Computer programs for detecting and correcting spelling errors.” 
                <span style="font-style:italic">Communications of the ACM</span>
            
             23.12 (December 1980): 676-687.
          </div>
					</li>
					<li id="index.xml-bibl-w785782aab3b3b1b1c33">
						<div class="biblfree">[Quin 2017] Quin, Liam. “Improving text quality with automatic majority editions: How shall I count the ways?”. In 
                <span style="font-style:italic">XML Prague 2017 Conference Proceedings.</span>
            
             University of Economics, Prague, February 9-11, 2017, pp. 33-45. On the web at http://archive.xmlprague.cz/2017/files/xmlprague-2017-proceedings.pdf. The digitized edition of Chalmers is on the web at 
                <a class="link_ptr" href="https://words.fromoldbooks.org/Chalmers-Biography/">
								<span>https://words.fromoldbooks.org/Chalmers-Biography/</span>
							</a>
            
            .
          </div>
					</li>
				</ol>
			</div>
			<!--Notes in [TEI]-->
			<div class="notes">
				<div class="noteHeading">Notes</div>
				<div class="note" id="ftn0">
					<span class="noteLabel">i </span>
					<div class="noteBody">The Wittgenstein project defined standard orthography as that of Duden's 
              <span style="font-style:italic">Rechtschreibung,</span>
          
           but admitted some idiosyncratic spellings consistently used by Wittgenstein.
        </div>
				</div>
				<div class="note" id="ftn1">
					<span class="noteLabel">ii </span>
					<div class="noteBody">In principle, project-specific dictionaries should be built by proofreading texts one-by-one; to streamline the pilot project, we took the shortcut of checking wordlists against off-the-shelf dictionaries. This does not visibly affect the statistical results shown later, but it does mean that for Chalmers some mistranscriptions were missed and some bad flags thrown.</div>
				</div>
			</div>
			<hr/>
		</div>
	</body>
</html>
