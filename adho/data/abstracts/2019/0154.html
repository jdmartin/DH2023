<?xml version="1.0"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
		<!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
		<title>Lessons Learned in a Large-Scale Project to Digitize and Computationally Analyze Musical Scores</title>
		<meta name="author" content="Cory McKay , Julie E. Cumming and Ichiro Fujinaga"/>
		<meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
		<meta name="DC.Title" content="Lessons Learned in a Large-Scale Project to Digitize and Computationally Analyze Musical Scores"/>
		<meta name="DC.Type" content="Text"/>
		<meta name="DC.Format" content="text/html"/>
		<link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
		<link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
		<style>
 div.dh2019 { max-width:1000px; margin: auto;}
 body {
       font-family: verdana;
       font-size: 11px;
}
 p {
    font-family: verdana;
    font-size: 11px;
}
</style>
	</head>
	<body>
		<div class="dh2019">
			<img src="https://dev.clariah.nl/files/dh2019/logoos/EP_banner_DH20194.png" alt="DH2019 Utrecht University, The Netherlands" width="100%"/>
			<hr/>
			<br/>
			<div class="stdheader autogenerated">
				<h1 class="maintitle">Lessons Learned in a Large-Scale Project to Digitize and Computationally Analyze Musical Scores</h1>
			</div>
			<div class="stdfooter autogenerated">
				<address>Cory McKay (cory.mckay@mail.mcgill.ca), Marianopolis College, Canada and Julie E. Cumming (julie.cumming@mcgill.ca), McGill University, Canada and Ichiro Fujinaga (ichiro.fujinaga@mcgill.ca), McGill University, Canada</address>
			</div>
			<br/>
			<div class="dhconvalidator-xml-link"/>
			<!--TEI front-->
			<!--TEI body-->
			<p style="text-align:left; ">SIMSSA (Single Interface for Music Score Searching and Analysis) is an ambitious project that aims to unite, under a single framework, the ability to: </p>
			<ul>
				<li class="item">Transform images of musical scores into searchable digital symbolic representations using OMR (optical music recognition)</li>
				<li class="item">Computationally extract meaningful statistical information (features) from symbolic music files</li>
				<li class="item">Use machine learning and statistical analysis to conduct musicological research using this data</li>
				<li class="item">Create a framework for searching symbolic scores based on both metadata and musical content</li>
				<li class="item">Make the resulting information and tools easily accessible to other researchers</li>
			</ul>
			<p style="text-align:left; ">Much has been accomplished since SIMSSA was first presented at DH (Fujinaga and Hankinson, 2013), but we have also made missteps along the way. Both our successes and failures have provided insights applicable not only to the specialized fields of MIR (Schedl et al., 2014) and digital musicology, but also to the digital humanities in general. This paper is intended to share our experience with the DH community.</p>
			<p style="text-align:left; ">The proper construction of datasets is one area of central importance. Too often, researchers simply combine digitized data as is, from whatever sources are available, or digitize data themselves without first developing a carefully considered workflow. This can lead to erroneous conclusions, as false patterns may be observed based on inconsistent dataset construction practices rather than on the underlying information itself. Alternatively, meaningful patterns may be obscured by datasets that fail to capture essential information.</p>
			<p style="text-align:left; ">We encountered such problems when we carried out research on regional differences between Iberian and Franco-Flemish Renaissance music (McKay, 2018): individual transcribers had encoded note durations differently, so rhythm was correlated more with the transcriber than with the underlying music. Problems can also be introduced during the encoding process, as we observed when commercial score editing software confused the encoding of slurs and ties (Nápoles et al., 2018). We therefore developed a set of best practices to help avoid bias when constructing datasets from historical documents (Cumming et al., 2018).</p>
			<p style="text-align:left; ">Selection of data is also essential. Results can be compromised if a dataset does not represent the full range of relevant instances (e.g., only an artist’s early works) or contains uneven class distributions (e.g., many more works by one artist than another). For example, we observed in machine learning-based research on composer attribution (McKay et al., 2017b) that, if we did not carefully prepare our data, trained models would sometimes perform classifications based on genre rather than compositional style, since the number of masses and motets were not evenly distributed across composers. </p>
			<p style="text-align:left; ">Judicious application of machine learning is another central area of interest. Most current research emphasizes deep learning, where models are trained on huge datasets, with relatively generic pre-processing. This contrasts with more traditional approaches where training is performed on hand-crafted statistical features that quantify specific qualities of domain interest, or where sub-systems sequentially process data in stages following a pre-defined workflow. Deep learning and more traditional alternatives each have different strengths and weaknesses, which one must understand before choosing which to utilize.</p>
			<p style="text-align:left; ">The current emphasis on deep learning is understandable, given its widely documented success in many domains. We found, for example, that our OMR performance improved substantially when we switched from a traditional architecture to a deep learning framework that directly processes pixel windows (Calvo-Zaragoza et al., 2018). </p>
			<p style="text-align:left; ">Deep learning also has important limitations, however. Its need for huge training sets can be a serious limitation when dealing with historical data with limited extant instances, even when clever data augmentation techniques are used. This problem became apparent in our research on automatically harmonically analyzing chorales (Condit-Schultz et al., 2018), for example. Another important limitation is that deep learning, despite recent advances in model transparency, still often results in black-box classifiers. In contrast, feature-based systems (in conjunction with feature-selection algorithms) produce searchable data and directly accessible insights into how features differentiate classes in ways that are meaningful to domain experts. This can be even more important to DH research than class label outputs themselves.</p>
			<p style="text-align:left; ">As an illustration of the potential advantages of a feature-based approach, we used 1497 features extracted by our jSymbolic software (McKay et al., 2018) not only to train models that could correctly attribute the music of Renaissance composers (McKay et al., 2017b) and identify Renaissance genres (Cumming and McKay, 2018) with high accuracy, but also to gain novel musicological insights into which musical characteristics statistically differentiate these classes. We also empirically tested expert predications about musical style in these studies, 63% of which were found to be inaccurate. There is a particular need for such testing in the humanities, as there are many generally accepted assertions that have never been validated empirically. </p>
			<p style="text-align:left; ">We also used the jSymbolic features to provide content-based support (McKay et al., 2017a) for composer attribution confidence levels proposed by Rodin and Sapp (2015) based only on historical evidence. This is a nice example of how computational and traditional humanities research can complement one another. </p>
			<p style="text-align:left; ">It is also essential to consider issues associated with making research data, software and results available, useable and attractive to other researchers in the humanities, including those not yet accustomed to computational approaches. As noted by Wiering (2017), one must consult domain experts about what they need, rather than imposing decisions on them. Other priorities include: clean and consistent interfaces; clear and extensive documentation, including tutorials; adoption of open accepted standards; compatibility with diverse data formats; facilitating extensibility for other researchers; and careful consideration of data and software in the context of intellectual property laws.</p>
			<p style="text-align:left; ">The better DH researchers become at facilitating the sharing of data and software, the better we will be able to directly compare techniques and results across research groups. This will in turn permit experimental repeatability and validation, as well as encourage iterative refinements across groups. Researchers will be better able to explore data in new ways and subject long-standing assumptions to empirical validation, arguably the two greatest benefits computational approaches bring to the humanities. We believe such steps will further expand the already excellent research underway in the digital humanities.</p>
			<!--TEI back-->
			<div class="bibliogr" id="index.xml-back.1_div.1">
				<h2>
					<span class="headingNumber">Appendix A </span>
				</h2>
				<div class="listhead">Bibliography</div>
				<ol class="listBibl">
					<li id="index.xml-bibl-w1497232aab3b3b1b1b3">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Calvo-Zaragoza, J., Castellanos, F. J., Vigliensoni, G. and Fujinaga, I.</span>
            
             (2018). Deep neural networks for document processing of music score images. 
                <span style="font-style:italic">Applied Science</span>
            
            , 8(5): 654–675.
          </div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1b5">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Condit-Schultz, N., Ju, Y. and Fujinaga, I.</span>
            
             (2018). A flexible approach to automated harmonic analysis: Multiple annotations of chorales by Bach and Praetorius. 
                <span style="font-style:italic">Proceedings of the International Society for Music Information Retrieval Conference.</span>
            
             pp. 66–73.
          </div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1b7">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Cumming, J. and McKay, C.</span>
            
             (2018). Revisiting the origins of the Italian madrigal using machine learning. 
                <span style="font-style:italic">Medieval and Renaissance Music Conference.</span>
            
             p. 35.
          </div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1b9">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Cumming, J., McKay C., Stuchbery, J. and Fujinaga, I.</span>
            
             (2018). Methodologies for creating symbolic corpora of Western music before 1600. 
                <span style="font-style:italic">Proceedings of the International Society for Music Information Retrieval Conference.</span>
            
             pp. 491–498.
          </div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1c11">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Fujinaga, I. and Hankinson, A. </span>
            
            (2013). SIMSSA: Towards full-music search over a large collection of musical scores. 
                <span style="font-style:italic">Conference Abstracts of Digital Humanities.</span>
            
             pp. 187–189.
          </div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1c13">
						<div style="text-align:left; ">
							<span style="font-weight:bold">McKay, C., Cumming, J. and Fujinaga, I. </span>
            
            (2017a). Characterizing composers using jSymbolic2 features. 
                <span style="font-style:italic">Extended Abstracts for the Late-Breaking Demo Session of the 18th International Society for Music Information Retrieval Conference.</span>
						</div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1c15">
						<div style="text-align:left; ">
							<span style="font-weight:bold">McKay, C., Tenaglia, T., Cumming, J. and Fujinaga, I. </span>
            
            (2017b). Using statistical feature extraction to distinguish the styles of different composers. 
                <span style="font-style:italic">Medieval and Renaissance Music Conference.</span>
            
             p. 111.
          </div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1c17">
						<div style="text-align:left; ">
							<span style="font-weight:bold">McKay, C.</span>
            
             (2018). Performing statistical musicological research using jSymbolic and machine learning. 
                <span style="font-style:italic">The Anatomy of Polyphonic Music around 1500 International Conference.</span>
            
             pp. 34–35.
          </div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1c19">
						<div style="text-align:left; ">
							<span style="font-weight:bold">McKay, C., Cumming J. and Fujinaga, I. </span>
            
            (2018). jSymbolic 2.2: Extracting features from symbolic music for use in musicological and MIR research. 
                <span style="font-style:italic">Proceedings of the International Society for Music Information Retrieval Conference.</span>
            
             pp. 348–354.
          </div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1c21">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Nápoles Lopez, N., Vigliensoni, G. and I. Fujinaga.</span>
            
             (2018). Encoding matters. 
                <span style="font-style:italic">Proceedings of the International Conference on Digital Libraries for Musicology.</span>
            
             pp. 69–73.
          </div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1c23">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Rodin, J. and Sapp, C. </span>
            
            (2015). The Josquin Research Project, http://josquin.stanford.edu/about/attribution (accessed 13 November 2018).
          </div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1c25">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Schedl, M., Gómez, E. and Urbano, J. </span>
            
            (2014). Music information retrieval: Recent developments and applications. 
                <span style="font-style:italic">Foundations and Trends in Information Retrieval,</span>
            
             8(2–3): 127–261.
          </div>
					</li>
					<li id="index.xml-bibl-w1497232aab3b3b1b1c27">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Wiering, F. </span>
            
            (2017). The software of your dreams: Expectations and realities in the use of technology in music research. Congress of the International Musicological Society. pp. 212–213.
          </div>
					</li>
				</ol>
			</div>
			<hr/>
		</div>
	</body>
</html>
