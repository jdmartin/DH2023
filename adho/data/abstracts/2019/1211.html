<?xml version="1.0"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
		<!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
		<title>Deciphering Lyrical Topics in Music and Their Connection to Audio Feature Dimensions Based on a Corpus of Over 100.000 Metal Songs </title>
		<meta name="author" content="Isabella Czedik-Eysenberg and Oliver Wieczorek"/>
		<meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
		<meta name="DC.Title" content="Deciphering Lyrical Topics in Music and Their Connection to Audio Feature Dimensions Based on a Corpus of Over 100.000 Metal Songs"/>
		<meta name="DC.Type" content="Text"/>
		<meta name="DC.Format" content="text/html"/>
		<link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
		<link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
		<style>
 div.dh2019 { max-width:1000px; margin: auto;}
 body {
       font-family: verdana;
       font-size: 11px;
}
 p {
    font-family: verdana;
    font-size: 11px;
}
</style>
	</head>
	<body>
		<div class="dh2019">
			<img src="https://dev.clariah.nl/files/dh2019/logoos/EP_banner_DH20194.png" alt="DH2019 Utrecht University, The Netherlands" width="100%"/>
			<hr/>
			<br/>
			<div class="stdheader autogenerated">
				<h1 class="maintitle">
					<span class="titlem">Deciphering Lyrical Topics in Music and Their Connection to Audio Feature Dimensions Based on a Corpus of Over 100.000 Metal Songs</span>
					<span class="titlem"/>
				</h1>
			</div>
			<div class="stdfooter autogenerated">
				<address>Isabella Czedik-Eysenberg (isabella.czedik-eysenberg@univie.ac.at), University of Vienna, Austria and Oliver Wieczorek (oliver.wieczorek@uni-bamberg.de), Otto-Friedrich-University Bamberg</address>
			</div>
			<br/>
			<div class="dhconvalidator-xml-link"/>
			<!--TEI front-->
			<!--TEI body-->
			<p>
				<div style="float:right; ">
					<img src="../posters/1211.jpg" style="width:300px;float:right;margin-left: 5px"/>
				</div>
      
      As audio and text features provide complementary layers of information on songs, a combination of both data types has been shown to improve automatic classification of high-level attributes in music such as genre, mood and emotion (Neumayer and Rauber, 2007; Laurier et al., 2008; Hu and Downie, 2010; Kim, 2010). Multi-modal approaches interlinking these features offer insights into possible relations between lyrical and musical information (see Nichols et al., 2009; McVicar et al., 2011; Yu et al. 2019).</p>
			<p>Therefore, we examine the connection between audio features and the lyrical content of metal music by combining automated extraction of high-level music properties and quantitative text analysis on a large corpus of music from this genre. Sound dimensions like loudness, distortion and particularly “hardness”/“heaviness” play an essential role in defining the sound of metal music (Reyes, 2008; Mynett, 2013; Herbst, 2017). Topics typically ascribed to metal lyrics contain sadness, death, freedom, nature, occultism or unpleasant/disgusting objects and are often labeled as brutal, dystopian or satanistic (Bayer, 2016; Cheung and Feng, 2019; Podoshen et al., 2014).</p>
			<p>By combining both audio feature and text analysis, we (1) offer a comprehensive overview of the lyrical topics present within the metal genre and (2) are able to address whether or not levels of "hardness” and other music dimensions are associated with the occurrence of brutal (and other) textual topics.</p>
			<p>Methodically, our research builds on a previous examination (Czedik-Eysenberg, 2018), in which ratings were obtained for 212 music stimuli by 40 raters each. Based on this music perception study, prediction models for the automatic extraction of high-level audio feature dimensions like “hardness” and “darkness” had been trained via machine learning methods.</p>
			<p>Now, in our most recent complementary step, we programmed a web crawler to automatically retrieve metal music lyrics from www.darklyrics.com, resulting in a sample of 152.916 song texts. After cleaning procedures, our subsample included 124.288 texts. We applied latent Dirichlet allocation (Blei et al., 2003) on the remaining subsample to construct a probabilistic topic model. Log-perplexity and log UMass coherence were used as goodness-of-fit measures evaluating topic models ranging from 10 to 100 topics. We then examined the most salient and most typical words for each topic. Additionally, within the topic configuration, we identified a latent dimension where philosophical and brutal topics oppose texts with shallow content.</p>
			<p>Results of the investigation for relations between high-level audio features and lyrical topics will be presented and the topic models will be displayed to visitors during the poster session for interactive exploration.</p>
			<!--TEI back-->
			<div class="bibliogr" id="index.xml-back.1_div.1">
				<h2>
					<span class="headingNumber">Appendix A </span>
				</h2>
				<div class="listhead">Bibliography</div>
				<ol class="listBibl">
					<li id="index.xml-bibl-w11905914aab3b3b1b1b3">
						<div class="biblfree">
							<span style="font-weight:bold">Bayer, G.</span>
            
             (2016). Images of human-wrought despair and destruction: Social critique in British apocalyptic and dystopian metal. In Gerd Bayer (ed), 
                <span style="font-style:italic">Heavy metal music in Britain</span>
            
            . Routledge, pp. 101-22.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1b5">
						<div class="biblfree">
							<span style="font-weight:bold">Blei, D. M., Ng, A. Y., </span>
							<span style="font-weight:bold">and</span>
							<span style="font-weight:bold">Jordan, M. I.</span>
            
             (2003). Latent dirichlet allocation. 
                <span style="font-style:italic">Journal of machine Learning research</span>
            
            , 3: 993-1022.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1b7">
						<div class="biblfree">
							<span style="font-weight:bold">Cheung, J. O., &amp; Feng, D.</span>
            
             (2019). Attitudinal meaning and social struggle in heavy metal song lyrics: a corpus-based analysis. 
                <span style="font-style:italic">Social Semiotics:</span>
            
             1-18.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1b9">
						<div class="biblfree">
							<span style="font-weight:bold">Czedik-Eysenberg, I., Reuter, C., &amp; Knauf, D. </span>
            
            (2018). 
                <em>Decoding the sound of ‘hardness’ and ‘darkness’ as perceptual dimensions of music</em>
            
            . 
                <span style="font-style:italic">I</span>
							<span style="font-style:italic">CMPC</span>
							<span style="font-style:italic">-</span>
							<span style="font-style:italic">ESCOM: </span>
							<span style="font-style:italic">Book of Abstracts</span>
            
            . Graz, pp. 112-13.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1c11">
						<div class="biblfree">
							<span style="font-weight:bold">Herbst, J.-P. </span>
            
            (2017). Historical development, sound aesthetics and production techniques of the distorted electric guitar in metal music. 
                <span style="font-style:italic">Metal Music Studies</span>
            
            , 3(1): 23-46.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1c13">
						<div class="biblfree">
							<span style="font-weight:bold">Hu, X., &amp; Downie, J. S.</span>
            
             (2010). Improving mood classification in music digital libraries by combining lyrics and audio. 
                <span style="font-style:italic">Proceedings of the 10th annual joint conference on Digital libraries</span>
            
            . ACM, pp. 159-68.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1c15">
						<div class="biblfree">
							<span style="font-weight:bold">Kim, Y. E., Schmidt, E. M., Migneco, R., Morton, B. G., Richardson, P., Scott, J., </span>
							<span style="font-weight:bold">Speck, J.A.</span>
							<span style="font-weight:bold">Turnbull, D.</span>
            
             (2010). Music emotion recognition: A state of the art review. 
                <span style="font-style:italic">ISMIR</span>
            
            , pp. 937-52.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1c17">
						<div class="biblfree">
							<span style="font-weight:bold">Laurier, C., Grivolla, J., &amp; Herrera, P. </span>
            
            (2008). Multimodal music mood classification using audio and lyrics. 
                <span style="font-style:italic">Seventh International Conference on Machine Learning and Applications</span>
            
            . IEEE, pp. 688-93.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1c19">
						<div class="biblfree">
							<span style="font-weight:bold">McVicar, M., Freeman, T., &amp; De Bie, T.</span>
            
             (2011). Mining the Correlation between Lyrical and Audio Features and the Emergence of Mood. 
                <span style="font-style:italic">ISMIR</span>
            
            , pp. 783-88.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1c21">
						<div class="biblfree">
							<span style="font-weight:bold">Mynett, M.</span>
            
             (2013). 
                <span style="font-style:italic">Contemporary metal music production</span>
            
            . Dissertation, University of Huddersfield.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1c23">
						<div class="biblfree">
							<span style="font-weight:bold">Neumayer, R., &amp; Rauber, A.</span>
            
             (2007). Integration of text and audio features for genre classification in music information retrieval. 
                <span style="font-style:italic">European Conference on Information Retrieval</span>
            
            , pp. 724-27.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1c25">
						<div class="biblfree">
							<span style="font-weight:bold">Nichols, E., Morris, D., Basu, S., </span>
							<span style="font-weight:bold">and</span>
							<span style="font-weight:bold">Raphael, C.</span>
            
             (2009). Relationships between lyrics and melody in popular music. 
                <span style="font-style:italic">ISMIR</span>
            
            , pp. 471–76.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1c27">
						<div class="biblfree">
							<span style="font-weight:bold">Podoshen, J. S., Venkatesh, V., &amp; Jin, Z.</span>
            
             (2014). Theoretical reflections on dystopian consumer culture: Black metal. 
                <span style="font-style:italic">Marketing Theory</span>
            
            , 14(2): 207-27.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1c29">
						<div class="biblfree">
							<span style="font-weight:bold">Reyes, I.</span>
            
             (2008). 
                <span style="font-style:italic">Sound, Technology, and interpretation in Subcultures of Heavy Music Production</span>
            
            . Dissertation, Pittsburgh University.
          </div>
					</li>
					<li id="index.xml-bibl-w11905914aab3b3b1b1c31">
						<div class="biblfree">
							<span style="font-weight:bold">Yu, Y., Tang, S., Raposo, F., &amp; Chen, L. </span>
            
            (2019). Deep cross-modal correlation learning for audio and lyrics in music retrieval. 
                <span style="font-style:italic">ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM)</span>
            
            , 15(1): 20-21.
          </div>
					</li>
				</ol>
			</div>
			<hr/>
		</div>
	</body>
</html>
