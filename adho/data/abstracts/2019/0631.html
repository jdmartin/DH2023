<?xml version="1.0"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
		<!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
		<title>A Predictive Approach to Semantic Change Modelling</title>
		<meta name="author" content="Mohamed Amine Boukhaled , Benjamin Fagard and Thierry Poibeau"/>
		<meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
		<meta name="DC.Title" content="A Predictive Approach to Semantic Change Modelling"/>
		<meta name="DC.Type" content="Text"/>
		<meta name="DC.Format" content="text/html"/>
		<link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
		<link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
		<style>
 div.dh2019 { max-width:1000px; margin: auto;}
 body {
       font-family: verdana;
       font-size: 11px;
}
 p {
    font-family: verdana;
    font-size: 11px;
}
</style>
	</head>
	<body>
		<div class="dh2019">
			<img src="https://dev.clariah.nl/files/dh2019/logoos/EP_banner_DH20194.png" alt="DH2019 Utrecht University, The Netherlands" width="100%"/>
			<hr/>
			<br/>
			<div class="stdheader autogenerated">
				<h1 class="maintitle">A Predictive Approach to Semantic Change Modelling</h1>
			</div>
			<div class="stdfooter autogenerated">
				<address>Mohamed Amine Boukhaled (amine.boukhaled@ens.fr), Laboratoire Langues, Textes, Traitements informatique, Cognition (Lattice, CNRS, ENS &amp; Université Paris 3) and Benjamin Fagard (benjamin.fagard@ens.fr), Laboratoire Langues, Textes, Traitements informatique, Cognition (Lattice, CNRS, ENS &amp; Université Paris 3) and Thierry Poibeau (thierry.poibeau@ens.fr), Laboratoire Langues, Textes, Traitements informatique, Cognition (Lattice, CNRS, ENS &amp; Université Paris 3)</address>
			</div>
			<br/>
			<div class="dhconvalidator-xml-link"/>
			<!--TEI front-->
			<!--TEI body-->
			<div class="DH-Heading1" id="index.xml-body.1_div.1">
				<h2 class="DH-Heading1">
					<span class="headingNumber">1. </span>
					<span class="head">Introduction </span>
				</h2>
				<p style="text-align:left; ">Although it is well known that word meanings evolve over time, there is still much to discover concerning the causes and pace of semantic change . In this context, computational modelling can shed new light on the problem by considering at the same time a large number of variables that are supposed to interact in a complex manner. This field has already given birth to a large number of publications ranging from early work involving statistical and mathematical formalism (Bailey, 1973 ; Kroch, 1989) to more recent work involving robotics and large-scale simulations (Steels, 2011). </p>
				<p style="text-align:left; ">We consider that semantic change includes all kinds of change in the meanings of lexical items happening over the years. For example, the word 
            <span style="font-style:italic">awful</span>
        
         has dramatically changed in meaning, moving away from a rather positive perspective equivalent to 
            <span style="font-style:italic">impressive</span>
        
         or 
            <span style="font-style:italic">majestic</span>
        
         at the beginning of the nineteenth century to a negative one equivalent to 
            <span style="font-style:italic">disgusting</span>
        
         and 
            <span style="font-style:italic">messy</span>
        
         nowadays (Wijaya and Yeniterzi, 2011).
      </p>
				<p style="text-align:left; ">In this work, we address the question of semantic change from a computational point of view. Our aim is to capture the systemic change of word meanings in an empirical model that is also predictive, contrary to most previous approaches that meant to reproduce empirical observations. We will first describe our methodology, then the experiment and our results, before concluding. </p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.2">
				<h2 class="DH-Heading1">
					<span class="headingNumber">2. </span>
					<span class="head">Proposed methodology</span>
				</h2>
				<p style="text-align:left; ">Our goal is to train a model representing semantic change over a certain period and, from there, to predict potential future semantic changes. The evaluation will thus be based on the observation of the gap between actual data and predicted data. </p>
				<p style="text-align:left; ">Our model is based on two main components: </p>
				<p style="text-align:left; ">
					<span style="font-style:italic">1- Diachronic word embeddings</span>
        
         representing the meaning of words over time-periods, following Turney and Pantel (2010). Word embeddings are known to effectively represent the meaning of words by taking into account their surrounding contexts. The representation can be extended to include a diachronic perspective: word embeddings are first trained for each time-period and then aligned temporally, so as to be able to track semantic change over time, see Fig. 1. For our study, we used the pre-trained diachronic word embeddings released by Hamilton et al. (2016): for each decade from 1800 to 1990, a specific word embedding is built using the word2vec skip gram algorithm. The training corpus used to produce these word embeddings was derived from the English Google Books N-gram datasets (Lin et al., 2012), which contain a large number of historical texts in many languages (we used 5-grams with no part-of-speech tags). Each word in the corpus appearing from 1800 to 1999 is represented by a set of twenty 300-dimensional vectors, with one vector per decade.
      </p>
				<div class="figure">
					<img src="Pictures/81f9e15e0e8793bca8fc3a114e70d8d9.png" alt="" class="inline" style=" width:16.012583333333332cm; height:4.416777777777778cm;"/>
				</div>
				<p style="text-align:left; ">Figure 1. Two-dimensional visualization of the semantic change in the English word “ 
            <span style="font-style:italic">cell</span>
        
        ” using diachronic word embedding. In the early 19th century the word cell was typically used to refer to a prison cell, hence the frequency of 
            <span style="font-style:italic">cage</span>
        
         and 
            <span style="font-style:italic">dungeon</span>
        
         in the context of 
            <span style="font-style:italic">cell </span>
        
        in 1800, whereas in the late 19th century its meaning changed as it came to be frequently used in a scientific context, referring to a microscopic part of a living being (see 
            <span style="font-style:italic">protoplasm</span>
        
        , 
            <span style="font-style:italic">ovum</span>
        
        , etc. in the 1900 context).
      </p>
				<p style="text-align:left; ">
					<span style="font-style:italic">2- Recurrent Neural Networks (RNNs)</span>
        
         modelling semantic change itself. RNNs are known to be powerful at recognizing dynamic temporal behaviours in diachronic data (Medsker and Jain, 2001). In this experiment, we used the word embeddings representing the semantic space of each decade from 1800 to 1990 as input for the RNN, and from this we predicted the embedding corresponding to the 1990-1999 decade. Our RNNs have a long short-term memory (LSTM) and are implemented through Tensorflow.
      </p>
				<p style="text-align:left; ">To explore different scenarios, we ran several experiments with different vocabulary sizes (restricted to the 1,000, 5,000, 10,000, 20,000 and 50,000 most frequent words). We used the stratified 10-fold cross-validation method to estimate the prediction error (i.e. 90% of the words were used for training, and 10% for testing). The overall prediction accuracy is taken as the average performance over these 10 runs. </p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.3">
				<h2 class="DH-Heading1">
					<span class="headingNumber">3. </span>
					<span class="head">Experiment, Results and Discussion</span>
				</h2>
				<p style="text-align:left; ">To get an overall estimation of the prediction accuracy, we compare each predicted embedding to the ground truth obtained from real data. Though it is impossible to predict exactly the vector corresponding to a given word “w”, as we are working in a continuous 300-dimensional space, one can assess the accuracy of the predicted meaning by extracting the closest vectors, i.e. the closest neighbours of a given word over time. </p>
				<p style="text-align:left; ">If the word “w” is actually the nearest semantic neighbour to the predicted vector, then it is considered to be a correct prediction. Otherwise, it is considered to be an error (a false prediction). The results are summarized in Table 1. </p>
				<div class="table">
					<table class="rules" style="border-collapse:collapse;border-spacing:0;">
						<tr>
							<td class="DH-Default">Vocabulary Size</td>
							<td class="DH-Default">Accuracy</td>
						</tr>
						<tr>
							<td class="DH-Default">1000</td>
							<td class="DH-Default">91.7%</td>
						</tr>
						<tr>
							<td class="DH-Default">5000</td>
							<td class="DH-Default">86.1%</td>
						</tr>
						<tr>
							<td class="DH-Default">10000</td>
							<td class="DH-Default">71.4%</td>
						</tr>
						<tr>
							<td class="DH-Default">20000</td>
							<td class="DH-Default">52.2%</td>
						</tr>
						<tr>
							<td class="DH-Default">50000</td>
							<td class="DH-Default">25%</td>
						</tr>
					</table>
				</div>
				<p style="text-align:left; ">
					<span style="font-weight:bold">Table 1.</span>
        
         Results of prediction accuracy measured for different vocabulary sizes. The training and the prediction using the RNNs model were performed on embeddings derived from the Google N-gram corpus.
      </p>
				<p style="text-align:left; ">The results show that the model can be highly effective at capturing semantic change, and can achieve a high accuracy when predicting the evolution of word meaning through distributional semantics. As one can see from Table 1, the model was able to achieve 71.4% accuracy when trained and tested exclusively on embeddings based on the 10,000 most frequent words of the corpus. The model was even able to correctly predict word embeddings for words that have radically changed their meaning over time such as 
            <span style="font-style:italic">awful</span>
        
        , 
            <span style="font-style:italic">nice</span>
        
        , 
            <span style="font-style:italic">cell</span>
        
         and 
            <span style="font-style:italic">record</span>
        
         (Wijaya and Yeniterzi, 2011).
      </p>
				<p style="text-align:left; ">The results also show better results when using smaller vocabulary sizes containing top frequent words. The decrease of performance with large vocabularies is due to the fact that infrequent words do not have enough occurrences to derive meaningful and stable enough contexts so as to observe reliable evolutions. It is thus fundamental to use large corpora for this kind of experiments, but also to adapt the size of the vocabulary to the size of the corpus. </p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.4">
				<h2 class="DH-Heading1">
					<span class="headingNumber">4. </span>
					<span class="head">Conclusion</span>
				</h2>
				<p style="text-align:left; ">We have proposed a new computational model of semantic change. Although this model is (partially) successful at representing this evolution, it can still appear to be too simple compared to the complexity of language change in general and semantic change in particular. For now, it may remain hard to understand precisely how this type of computational modelling can be combined with more traditional methods of linguistic analysis. However, we strongly believe that such empirical approaches based on diachronic vector-based representations can considerably help to refine and clarify theoretical insights on the foundations and mechanisms of semantic change, as well as provide an accurate empirical evaluation.</p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.5">
				<h2 class="DH-Heading1">
					<span class="headingNumber">5. </span>
					<span class="head">Acknowledgements</span>
				</h2>
				<p style="text-align:left; ">This work is supported by the project 2016-147 ANR OPLADYN TAP-DD2016. Thierry Poibeau is also supported by the CNRS International Research Network “Cyclades”. Our thanks go to the anonymous reviewers for their constructive comments.</p>
			</div>
			<!--TEI back-->
			<div class="bibliogr" id="index.xml-back.1_div.1">
				<h2>
					<span class="headingNumber">Appendix A </span>
				</h2>
				<div class="listhead">Bibliography</div>
				<ol class="listBibl">
					<li id="index.xml-bibl-w7495762aab3b3b1b1b3">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Bailey, C.-J.N.</span>
            
             (1973). Variation and linguistic theory. Arlington: Centre for Applied Linguistics.
          </div>
					</li>
					<li id="index.xml-bibl-w7495762aab3b3b1b1b5">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Hamilton, W.L., Leskovec, J. and Jurafsky, D.</span>
            
             (2016). Diachronic word embeddings reveal statistical laws of semantic change. 
                <span style="font-style:italic">Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics</span>
            
            , 1489–1501.
          </div>
					</li>
					<li id="index.xml-bibl-w7495762aab3b3b1b1b7">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Kroch, A.S.</span>
            
             (1989). Reflexes of grammar in patterns of language change. 
                <span style="font-style:italic">Language Variation and Change</span>
            
            , 
                <span style="font-weight:bold">1</span>
            
            : 199–244.
          </div>
					</li>
					<li id="index.xml-bibl-w7495762aab3b3b1b1b9">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Lin, Y., Michel, J.-B., Aiden, E.L., Orwant, J., Brockman, W., Petrov, S.</span>
            
             (2012). Syntactic annotations for the google books Ngram corpus. 
                <span style="font-style:italic">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</span>
            
            : 169–174.
          </div>
					</li>
					<li id="index.xml-bibl-w7495762aab3b3b1b1c11">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Medsker, L.R. and Jain, L.C.</span>
            
             (2001). Recurrent neural networks. Boca Raton: CRC Press.
          </div>
					</li>
					<li id="index.xml-bibl-w7495762aab3b3b1b1c13">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Steels, L.</span>
            
             (2011). Modeling the cultural evolution of language. 
                <span style="font-style:italic">Physical Life Review</span>
            
            , 
                <span style="font-weight:bold">8</span>
            
            : 339–356.
          </div>
					</li>
					<li id="index.xml-bibl-w7495762aab3b3b1b1c15">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Turney, P.D. and Pantel, P.</span>
            
             (2010). From frequency to meaning: Vector space models of semantics. 
                <span style="font-style:italic">Journal of Artificial Intelligence Research</span>
            
            , 
                <span style="font-weight:bold">37</span>
            
            : 141–188.
          </div>
					</li>
					<li id="index.xml-bibl-w7495762aab3b3b1b1c17">
						<div style="text-align:left; ">
							<span style="font-weight:bold">Wijaya, D. and Yeniterzi, R.</span>
            
             (2011). Understanding Semantic Change of Words Over Centuries. In the 
                <span style="font-style:italic">Workshop on Detecting and Exploiting Cultural Diversity on the Social Web </span>
            
            (DETECT 2011) during CIKM 2011.
          </div>
					</li>
				</ol>
			</div>
			<hr/>
		</div>
	</body>
</html>
