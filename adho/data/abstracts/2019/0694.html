<?xml version="1.0"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
		<!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
		<title>Improving OCR of Black Letter in Historical Newspapers: The Unreasonable Effectiveness of HTR Models on Low-Resolution Images </title>
		<meta name="author" content="Phillip Benjamin Ströbel and Simon Clematide"/>
		<meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
		<meta name="DC.Title" content="Improving OCR of Black Letter in Historical Newspapers: The Unreasonable Effectiveness of HTR Models on Low-Resolution Images"/>
		<meta name="DC.Type" content="Text"/>
		<meta name="DC.Format" content="text/html"/>
		<link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
		<link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
		<style>
 div.dh2019 { max-width:1000px; margin: auto;}
 body {
       font-family: verdana;
       font-size: 11px;
}
 p {
    font-family: verdana;
    font-size: 11px;
}
</style>
	</head>
	<body>
		<div class="dh2019">
			<img src="https://dev.clariah.nl/files/dh2019/logoos/EP_banner_DH20194.png" alt="DH2019 Utrecht University, The Netherlands" width="100%"/>
			<hr/>
			<br/>
			<div class="stdheader autogenerated">
				<h1 class="maintitle">
					<span class="titlem">Improving OCR of Black Letter in Historical Newspapers: The Unreasonable Effectiveness of HTR Models on Low-Resolution Images</span>
					<span class="titlem"/>
				</h1>
			</div>
			<div class="stdfooter autogenerated">
				<address>Phillip Benjamin Ströbel (pstroebel@cl.uzh.ch), University of Zurich, Switzerland and Simon Clematide (simon.clematide@cl.uzh.ch), University of Zurich, Switzerland</address>
			</div>
			<br/>
			<div class="dhconvalidator-xml-link"/>
			<!--TEI front-->
			<!--TEI body-->
			<div class="DH-Heading1" id="index.xml-body.1_div.1">
				<h2 class="DH-Heading1">
					<span class="headingNumber">1. </span>
					<span class="head">Introduction</span>
				</h2>
				<p>The quality of Optical Character Recognition (OCR) is a decisive factor for the application of text mining techniques on historical newspapers (Chiron et al., 2017; Walker et al., 2010; Strange et al., 2014). OCR for texts published in black letter is particularly challenging due to several factors: the low distinctiveness of characters, the change over time regarding vocabulary and spelling, the use of small font sizes, and the oftentimes poor paper quality.</p>
				<p>Holley (2009) argued that in light of the poor OCR quality in newspapers, a focus on manual crowd-correction is more promising than investments in software development. Although automatic OCR post-correction can improve the quality of the text, the methods often lack precision, are not robust enough, or require a lot of in-domain training data (Alex et al., 2012; Chiron et al., 2017).</p>
				<p>The problems are manifold and complex, but recent progress in neural OCR techniques promises significant improvements (Springmann and Lüdeling, 2016). These OCR models often outperform commercial systems like 
            <span style="font-weight:bold">ABBYY FineReader</span>
					<span style="font-weight:bold"/>
					<span id="ftn0_return">
						<a class="notelink" title="" href="#ftn0">
							<sup>1</sup>
						</a>
					</span>
					<span style="font-weight:bold"/>
        
        . However, the training of a neural system using open-source software (e.g., 
            <span style="font-weight:bold">Tesseract</span>
					<span style="font-weight:bold"/>
					<span id="ftn1_return">
						<a class="notelink" title="" href="#ftn1">
							<sup>2</sup>
						</a>
					</span>
					<span style="font-weight:bold"/>
        
        ) is demanding. Integrated handwritten text recognition and annotation platforms like 
            <span style="font-weight:bold">Transkribus</span>
					<span style="font-weight:bold"/>
					<span id="ftn2_return">
						<a class="notelink" title="" href="#ftn2">
							<sup>3</sup>
						</a>
					</span>
					<span style="font-weight:bold"/>
        
         facilitate the creation of a ground truth, as well as the training and application of neural and corpus-specific models for OCR.
      </p>
				<p>Transkribus was initially designed to decipher manuscripts 
            <span id="ftn3_return">
						<a class="notelink" title="see" href="#ftn3">
							<sup>4</sup>
						</a>
					</span>
        
        . It allows the manual transcription of uploaded documents so that they can be used as training material for 
            <span style="font-weight:bold">Handwritten Text Recognition</span>
        
         (HTR) models (Weidemann et al., 2017). A useful feature of Transkribus’ HTR models is that the recognition of printed texts works just as well as that of manuscripts. A few dozen of corrected pages are sufficient for high-quality OCR results.
      </p>
				<p>In this study we illustrate how to drastically improve OCR quality for black letter in newspapers with a modest amount of manual work for ground truth creation. The integration of HTR model training into the Transkribus platform enables Digital Humanists to leverage the performance of neural OCR without having to tackle unnecessary technicalities. In our experiments we additionally address the following questions. Robustness: Are HTR models reusable for material that varies in digitisation quality (medium-resolution scans from microfilm vs. high-resolution scans from paper). Transferability: How well does a model perform on another newspaper than the one it was trained on?</p>
			</div>
			<div class="div1" id="index.xml-body.1_div.2">
				<h2>
					<span class="headingNumber">2. </span>
					<span class="head">
						<a id="id_data-and-experiments">
							<!--anchor-->
						</a>
          
          Data and Experiments
        </span>
				</h2>
				<p>We use PDFs with medium-resolution images produced in 2005 from scanned microfilms of the German-language 
            <span style="font-weight:bold">Neue Zürcher Zeitung</span>
        
         (NZZ) for our experiments. The OCRed text stems from 
            <span style="font-weight:bold">ABBYY FineReader XIX</span>
					<span style="font-weight:bold"/>
					<span id="ftn4_return">
						<a class="notelink" title="" href="#ftn4">
							<sup>5</sup>
						</a>
					</span>
					<span style="font-weight:bold"/>
        
        , which was ABBYY’s product for 19th century black letter recognition at that time.
      </p>
				<p>The first experiment evaluates the differences between three OCR systems: (a) FineReader XIX (FRXIX) results from 2005, (b) ABBYY FineReader Server 11 (FRS11) results 
            <span id="ftn5_return">
						<a class="notelink" title="see , available within Transkribus" href="#ftn5">
							<sup>6</sup>
						</a>
					</span>
        
        , (c) Transkribus’ HTR model. Figure 1 shows example output from our three OCR systems.
      </p>
				<div class="figure">
					<img src="Pictures/43d1bacd66807525a4cf35690f3fa329.png" alt="Example excerpts with low-quality OCR from two pages of the NZZ (1819 left, 1859 right, red: FRXIX, blue: FRS11, green: Transkribus HTR)" class="graphic" width="100%"/>
					<div class="caption">Figure 1. Example excerpts with low-quality OCR from two pages of the NZZ (1819 left, 1859 right, red: FRXIX, blue: FRS11, green: Transkribus HTR)</div>
				</div>
				<p>In our second experiment we apply the HTR model trained on medium-resolution images to high-resolution images (400dpi) from 1899 digitised anew from paper in order to test the transferability of the model. We also analyse the performance of the HTR model in two other publications.</p>
				<div class="div2" id="index.xml-body.1_div.2_div.1">
					<h3>
						<span class="headingNumber">2.1. </span>
						<span class="head">
							<a id="id_creation-of-a-ground-truth-and-htr-model-training">
								<!--anchor-->
							</a>
            
            Creation of a ground truth and HTR model training
          </span>
					</h3>
					<p>The NZZ had been published in black letter from 1780 until 1947. We chose one title page per year at random from this period and loaded the image extracted from the PDF into Transkribus. We used the Transkribus internal FRS11 to recognise the text in the images and manually corrected words and baselines. The resulting ground truth of 167 pages contains 304,286 words and 43,151 lines. Depending on the amount of text on a page, the correction of a page including the baselines (needed to train the HTR model) takes between 1 and 2.5 hours. We used 90/10 split for training and testing the model.</p>
				</div>
				<div class="div2" id="index.xml-body.1_div.2_div.2">
					<h3>
						<span class="headingNumber">2.2. </span>
						<span class="head">
							<a id="id_evaluation">
								<!--anchor-->
							</a>
            
            Evaluation
          </span>
					</h3>
					<p>We use the bag-of-words F1-measure metrics of PRImA TextEval 1.4 
              <span id="ftn6_return">
							<a class="notelink" title="" href="#ftn6">
								<sup>7</sup>
							</a>
						</span>
          
           for evaluation. The F1-measure is the harmonic mean of precision and recall. Precision gives the percentage of OCRed words that are part of the ground truth, while recall measures the percentage of ground truth words that were found by the OCR system. By applying a bag-of-words approach, possible differences in layout recognition cannot distort the results.
        </p>
				</div>
			</div>
			<div class="div1" id="index.xml-body.1_div.3">
				<h2>
					<span class="headingNumber">3. </span>
					<span class="head">
						<a id="id_results-and-discussion">
							<!--anchor-->
						</a>
          
          Results
        </span>
				</h2>
				<p>Figure 2 shows the evaluation on all pages from the test set. The FRS11 (mean F1-measure 81.1%, SD 7.3%) beats the FRXIX (mean 67.8%, SD 11.1%) throughout. Our HTR model scores 97.0% (SD, 1.8%) on average and achieves significant improvements over both ABBYY products.</p>
				<div class="figure">
					<img src="Pictures/16f498cc6da6a09f06204600b60f7129.png" alt="Comparison between original FRXIX, FRS11, and Transkribus HTR." class="graphic" width="100%"/>
					<div class="caption">Figure 2. Comparison between original FRXIX, FRS11, and Transkribus HTR.</div>
				</div>
				<p>The application of our HTR model to five high-resolution images of newspaper pages from the NZZ shows accuracies of at least 98% and an average improvement of 4.24% over FRS11 (see Figure 3).</p>
				<div class="figure">
					<img src="Pictures/22e84f6523c4aa62b6c3f5166d3ef074.png" alt="Comparison between FRS11 and Transkribus HTR model on five high-resolution images from 1899." class="graphic" width="100%"/>
					<div class="caption">Figure 3. Comparison between FRS11 and Transkribus HTR model on five high-resolution images from 1899.</div>
				</div>
				<p>In terms of the transferability of our HTR model the average F1-measures of 98.6% (SD 1.9%) for the 
            <span style="font-weight:bold">Bundesblatt</span>
					<span style="font-style:italic"/>
        
        and 98.9% (SD 0.6%) for the 
            <span style="font-weight:bold">Neue Zuger Zeitung</span>
        
         over five pages each show that although the model has been trained on the NZZ, it is able to score equally high on different publications. The FRS11 reaches 92.4% (SD 2.7%) for the Bundesblatt and 88.4% (SD 3.7%) for the Neue Zuger Zeitung, showing the superiority of our HTR model.
      </p>
			</div>
			<div class="div1" id="index.xml-body.1_div.4">
				<h2>
					<span class="headingNumber">4. </span>
					<span class="head">
						<a id="id_conclusion">
							<!--anchor-->
						</a>
          
          Conclusion
        </span>
				</h2>
				<p>We have shown that Transkribus is an excellent tool for creating HTR models for the OCR of newspapers typeset in black letter. Even with a limited amount of training data (150 pages), our HTR model consistently outperforms state-of-the-art commercial software. Our HTR model trained on medium-resolution images digitised from microfilm still performs better than commercial software when applied to high-resolution images derived from paper originals.</p>
				<p>Given the availability and abundance of digitised historical material in the form of PDF files with poorly OCRed text, our findings showcase how digital humanists can improve their source material for text mining with a reasonable effort.</p>
			</div>
			<div class="div1" id="index.xml-body.1_div.5">
				<h2>
					<span class="headingNumber">5. </span>
					<span class="head">Acknowledgments</span>
				</h2>
				<p>We would like to express our gratitude to Günter Mühlberger and the Transkribus team for their support in training HTR models and partially correcting baselines of our ground truth. Moreover, we thank Camille Watter and Isabel Meraner for their help in the transcription process. This research is supported by the Swiss National Science Foundation under grant CR-SII5_173719.</p>
			</div>
			<!--TEI back-->
			<div class="bibliogr" id="index.xml-back.1_div.1">
				<h2>
					<span class="headingNumber">Appendix A </span>
				</h2>
				<div class="listhead">Bibliography</div>
				<ol class="listBibl">
					<li id="index.xml-bibl-w2296143aab3b3b1b1b3">
						<div class="biblfree">
							<span style="font-weight:bold">Alex, B., Grover, C., Klein, E., Tobin, R.</span>
            
             (2012). 
                <span style="font-style:italic">Digitised Historical Text: Does it have to be mediOCRe?</span>
            
            , in: KONVENS. pp. 401–409.
          </div>
					</li>
					<li id="index.xml-bibl-w2296143aab3b3b1b1b5">
						<div class="biblfree">
							<span style="font-weight:bold">Chiron, G., Doucet, A., Coustaty, M., Visani, M., Moreux, J.-P.</span>
            
             (2017). 
                <span style="font-style:italic">Impact of OCR Errors on the Use of Digital Libraries: Towards a Better Access to Information</span>
            
            . 
                <span style="font-style:italic">2017 ACM/IEEE Joint Conference on Digital Libraries (JCDL)</span>
            
            . IEEE. 
                <a class="link_ptr" href="https://doi.org/10.1109/jcdl.2017.7991582">
								<span>https://doi.org/10.1109/jcdl.2017.7991582</span>
							</a>
						</div>
					</li>
					<li id="index.xml-bibl-w2296143aab3b3b1b1b7">
						<div class="biblfree">
							<span style="font-weight:bold">Holley, R.</span>
            
             (2009). 
                <span style="font-style:italic">How Good Can It Get? Analysing and Improving OCR Accuracy in Large Scale Historic Newspaper Digitisation Programs</span>
            
            . D-Lib Magazine 15. 
                <a class="link_ptr" href="https://doi.org/10.1045/march2009-holley">
								<span>https://doi.org/10.1045/march2009-holley</span>
							</a>
						</div>
					</li>
					<li id="index.xml-bibl-w2296143aab3b3b1b1b9">
						<div class="biblfree">
							<span style="font-weight:bold">Springmann, U., Lüdeling, A.</span>
            
             (2016). 
                <span style="font-style:italic">OCR of Historical Printings with an Application to Building Diachronic Corpora: A Case Study Using the RIDGES Herbal Corpus</span>
            
            . CoRR abs/1608.02153.
          </div>
					</li>
					<li id="index.xml-bibl-w2296143aab3b3b1b1c11">
						<div class="biblfree">
							<span style="font-weight:bold">Strange, C., McNamara, D., Wodak, J., Wood, I.</span>
            
             (2014). Mining for the Meanings of a Murder: The Impact of OCR Quality on the Use of Digitized Historical Newspapers. 
                <span style="font-style:italic">DHQ: Digital Humanities Quarterly 8</span>
            
            .
          </div>
					</li>
					<li id="index.xml-bibl-w2296143aab3b3b1b1c13">
						<div class="biblfree">
							<span style="font-weight:bold">Walker, D. D., Lund, W. B., Ringger, E. K.</span>
            
             (2010). 
                <span style="font-style:italic">Evaluating Models of Latent Document Semantics in the Presence of OCR Errors</span>
            
            . 
                <span style="font-style:italic">Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing</span>
            
            . Association for Computational Linguistics, pp. 240–250.
          </div>
					</li>
					<li id="index.xml-bibl-w2296143aab3b3b1b1c15">
						<div class="biblfree">
							<span style="font-weight:bold">Weidemann, M., Michael, J., Grüning, T., Labahn, R.</span>
            
             (2017). 
                <span style="font-style:italic">HTR Engine Based on NNs P2 Building Deep Architectures with TensorFlow</span>
            
            . 
                <a class="link_ptr" href="https://read.transkribus.eu/wp-content/uploads/2017/12/Del_D7_8.pdf">
								<span>https://read.transkribus.eu/wp-content/uploads/2017/12/Del_D7_8.pdf</span>
							</a>
						</div>
					</li>
				</ol>
			</div>
			<!--Notes in [TEI]-->
			<div class="notes">
				<div class="noteHeading">Notes</div>
				<div class="note" id="ftn0">
					<span class="noteLabel">1. </span>
					<div class="noteBody">
						<a class="link_ptr" href="https://www.abbyy.com">
							<span>https://www.abbyy.com</span>
						</a>
					</div>
				</div>
				<div class="note" id="ftn1">
					<span class="noteLabel">2. </span>
					<div class="noteBody">
						<a class="link_ptr" href="https://github.com/tesseract-ocr/tesseract">
							<span>https://github.com/tesseract-ocr/tesseract</span>
						</a>
					</div>
				</div>
				<div class="note" id="ftn2">
					<span class="noteLabel">3. </span>
					<div class="noteBody">
						<a class="link_ptr" href="https://www.transkribus.eu">
							<span>https://www.transkribus.eu</span>
						</a>
					</div>
				</div>
				<div class="note" id="ftn3">
					<span class="noteLabel">4. </span>
					<div class="noteBody">see 
              <a class="link_ptr" href="https://read.transkribus.eu/">
							<span>https://read.transkribus.eu/</span>
						</a>
					</div>
				</div>
				<div class="note" id="ftn4">
					<span class="noteLabel">5. </span>
					<div class="noteBody">
						<a class="link_ptr" href="https://www.frakturschrift.com/de:products:finereaderxix">
							<span>https://www.frakturschrift.com/de:products:finereaderxix</span>
						</a>
					</div>
				</div>
				<div class="note" id="ftn5">
					<span class="noteLabel">6. </span>
					<div class="noteBody">see 
              <a class="link_ptr" href="https://www.abbyy.com/de-de/finereader-server/">
							<span>https://www.abbyy.com/de-de/finereader-server/</span>
						</a>
          
          , available within Transkribus
        </div>
				</div>
				<div class="note" id="ftn6">
					<span class="noteLabel">7. </span>
					<div class="noteBody">
						<a class="link_ptr" href="https://www.primaresearch.org/tools/PerformanceEvaluation">
							<span>https://www.primaresearch.org/tools/PerformanceEvaluation</span>
						</a>
					</div>
				</div>
			</div>
			<hr/>
		</div>
	</body>
</html>
