<?xml version="1.0"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
		<!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
		<title>Kraken - an Universal Text Recognizer for the Humanities </title>
		<meta name="author" content="Benjamin Kiessling"/>
		<meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
		<meta name="DC.Title" content="Kraken - an Universal Text Recognizer for the Humanities"/>
		<meta name="DC.Type" content="Text"/>
		<meta name="DC.Format" content="text/html"/>
		<link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
		<link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
		<style>
 div.dh2019 { max-width:1000px; margin: auto;}
 body {
       font-family: verdana;
       font-size: 11px;
}
 p {
    font-family: verdana;
    font-size: 11px;
}
</style>
	</head>
	<body>
		<div class="dh2019">
			<img src="https://dev.clariah.nl/files/dh2019/logoos/EP_banner_DH20194.png" alt="DH2019 Utrecht University, The Netherlands" width="100%"/>
			<hr/>
			<br/>
			<div class="stdheader autogenerated">
				<h1 class="maintitle">
					<span class="titlem">Kraken - an Universal Text Recognizer for the Humanities</span>
					<span class="titlem"/>
				</h1>
			</div>
			<div class="stdfooter autogenerated">
				<address>Benjamin Kiessling (benjamin.kiessling@psl.eu), Universit√© PSL, France; Leipzig University</address>
			</div>
			<br/>
			<div class="dhconvalidator-xml-link"/>
			<!--TEI front-->
			<!--TEI body-->
			<div class="DH-Heading" id="index.xml-body.1_div.1">
				<h2 class="DH-Heading">
					<span class="headingNumber">1. </span>
					<span class="head">Introduction</span>
				</h2>
				<p>Retrodigitization of both printed and handwritten material is a common prerequisite for a diverse range of research questions in the humanities. While optical character recognition on printed texts is widely considered to be fundamentally solved in academia, with the most commonly used paradigm (Graves et al., 2006) dating back to 2006, this hasn't translated into increased availability of adaptable, libre-licensed OCR engines to the technically inclined humanities scholar.</p>
				<p>The nature of the material of interest commands a platform that can be altered with minimum effort to achieve optimal recognition accuracy; uncommon scripts, historical languages, complex or archaic page layout, and non-paper writing surfaces are rarily satisfactorily addressed by off-the-shelf commercial solutions. In addition, an open system ameliorates the severe resource constraints of humanities research by enabling sharing of artifacts, such as training data and recognition models, inaccessible with proprietary OCR technology.</p>
			</div>
			<div class="DH-Heading" id="index.xml-body.1_div.2">
				<h2 class="DH-Heading">
					<span class="headingNumber">2. </span>
					<span class="head">Kraken</span>
				</h2>
				<p>The Kraken text recognition engine is an extensively rewritten fork of the OCRopus system. It can be used both for handwriting and printed text recognition, is easily (re-)trainable, and great care has been taken to eliminate implicit assumptions on content and layout that complicate the processing of non-Latin and non-modern works.</p>
				<p>Thus Kraken has been extended with features and interfaces enabling the processing of most scripts, among them full Unicode right-to-left, bidirectional, and vertical writing support, script detection, and multiscript recognition. Processing of scripts not included in Unicode is also possible through a simple JSON interface to the codec mapping numerical model outputs to characters. The same interface provides facilities for efficient recognition of large logographic scripts.</p>
				<p>Output includes fine-grained bounding boxes down to the character level that may be used to quickly acquire a large number of samples from a corpus to assist in paleographic research. Kraken implements a flexible output serialization scheme utilizing a simple templating language. Templates are available for the most commonly used formats ALTO, hOCR, TEI, and abbyyXML.</p>
				<p>While including implementations of all the subprocesses needed in a text recognition pipeline, most functional blocks can be accessed separately on the command line, allowing flexible substitution of specially optimized methods. A stable programming interface allows total customization and integration into other software packages.</p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.3">
				<h2 class="DH-Heading1">
					<span class="headingNumber">3. </span>
					<span class="head">Recognition</span>
				</h2>
				<div class="figure">
					<img src="Pictures/1c3fc65599505037c8cac817a5c72615.png" alt="Network architecture (H: sequence height, W: sequence length, C: alphabet size)" class="graphic" width="100%"/>
					<div class="caption">Figure 1. Network architecture (H: sequence height, W: sequence length, C: alphabet size)</div>
				</div>
				<p>The recognition engine operates as a segmentation-less sequence classifier using an artificial neural network to map an image of a single line of text, the input sequence, into a sequence of characters, the output sequence. The artificial neural network employed is a hybrid convolutional and recurrent neural network trained with the CTC loss function (Graves et al., 2006) that reduces training data requirements to line-level transcriptions (Figure 3). Regularization is mainly provided by dropout (Hinton et al., 2012) after both convolutional and recurrent layers. User intervention in determining training duration and model selection is largely eliminated through early stopping.</p>
				<p>Specialized networks, e.g. for particularly complex scripts, can be assembled from building blocks with a simple network specification language although the default architecture shown in Figure 1 is suitable for the vast majority of applications.</p>
				<p>Processing of dictionaries and library catalogues with extensive semantic markup such as italic, underlining, and bolding, is also possible through specially prepared training data.</p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.4">
				<h2 class="DH-Heading1">
					<span class="headingNumber">4. </span>
					<span class="head">Layout Analysis and Script Detection</span>
				</h2>
				<div class="figure">
					<img src="Pictures/88bf936743d1a444d5c0d85be2449a0d.jpg" alt="Sample output of the trainable segmentation method." class="graphic" width="100%"/>
					<div class="caption">Figure 2. Sample output of the trainable segmentation method.</div>
				</div>
				<p>Kraken's layout analysis extracts text lines from an input image for later processing by the recognition engine. Apart from a basic segmenter taken from OCRopus a trainable line extractor is in the process of being implemented. Full trainability of layout analysis is of utmost importance to a truly universal OCR system, as text layout and its semantics varies widely across time and space, e.g. hand-crafted methods for printed Latin text are unlikely to work reliably on Arabic text or manuscripts with extensive interlinear annotation.</p>
				<p>The trainable layout analysis module consists of a two-step instance segmentation method: an initial seed-labelling network operates on the whole page labelling the area between baseline and mean of each line. As the output of the network is a probability of each pixel belonging to a baseline it is binarized using hysteresis thresholding after smoothing with a gaussian filter. The binarized image is then skeletonized and end point are extracted with a discrete convolution. Finally, the vectorized baseline between the endpoints is rectified and a variable environment calculated based on the distance of connected components from the labelled area is extracted.</p>
				<p>The seed-labelling network is a modified U-net (Ronneberger et al., 2015) on the basis of a 34-layer residual network (He et al., 2016) pretrained on ImageNet. </p>
				<p>Preliminary results on a page from a publicly available dataset of Arabic and Persian manuscripts (Kiessling et al., 2019) can be seen in Figure 2.</p>
				<p>Script detection, the basis for multi-script support in the recognizer, is implemented as a segmentation-less sequence classification problem, similar to text recognition. Instead of assigning a unique label to each code point or grapheme cluster we assign all code points of a particular script the same label. The network is then trained to output the correct sequence of script labels (Figure 3). The output sequence is then used to split the line into single-script runs that can be classified with monolingual recognition models (Figure 4).</p>
				<div class="figure">
					<img src="Pictures/b7a30ed8865c06cc82568cbae3750e0e.png" alt="Original and modified ground truth (top: original line, middle: transcription, bottom: assigned script classes)" class="graphic" width="100%"/>
					<div class="caption">Figure 3. Original and modified ground truth (top: original line, middle: transcription, bottom: assigned script classes)</div>
				</div>
			</div>
			<div class="DH-Heading" id="index.xml-body.1_div.5">
				<h2 class="DH-Heading">
					<span class="headingNumber">5. </span>
					<span class="head">Results</span>
				</h2>
				<div class="table" id="Table1">
					<table class="frame" style="border-collapse:collapse;border-spacing:0;">
						<tr>
							<td/>
							<td class="start color(#000000)bold">Mean character accuracy</td>
							<td class="start color(#000000)bold">Standard deviation</td>
							<td class="start color(#000000)bold">Maximum accuracy</td>
						</tr>
						<tr>
							<td class="start color(#000000)bold">Prints</td>
							<td/>
							<td/>
							<td/>
						</tr>
						<tr>
							<td class="start color(#000000)">Arabic (Kiessling et al., 2017)</td>
							<td class="start color(#000000)">99.5%</td>
							<td class="start color(#000000)">0.05</td>
							<td class="start color(#000000)">99.6%</td>
						</tr>
						<tr>
							<td class="start color(#000000)">Persian 
                  <span id="ftn4_return">
									<a class="notelink" title="Mid-20th century printing" href="#ftn4">
										<sup>1</sup>
									</a>
								</span>
							</td>
							<td class="start color(#000000)">98.3%</td>
							<td class="start color(#000000)">0.33</td>
							<td class="start color(#000000)">98.7%</td>
						</tr>
						<tr>
							<td class="start color(#000000)">Syriac 
                  <span id="ftn3_return">
									<a class="notelink" title="Late-19th century printing in Ser·π≠ƒÅ form" href="#ftn3">
										<sup>2</sup>
									</a>
								</span>
							</td>
							<td class="start color(#000000)">98.7%</td>
							<td class="start color(#000000)">0.38</td>
							<td class="start color(#000000)">99.2%</td>
						</tr>
						<tr>
							<td class="start color(#000000)">Polytonic Greek 
                  <span id="ftn2_return">
									<a class="notelink" title="Late-19th century printing" href="#ftn2">
										<sup>3</sup>
									</a>
								</span>
							</td>
							<td class="start color(#000000)">99.2%</td>
							<td class="start color(#000000)">0.26</td>
							<td class="start color(#000000)">99.6%</td>
						</tr>
						<tr>
							<td class="start color(#000000)">Latin (Springmann et al., 2018)</td>
							<td class="start color(#000000)">98.8%</td>
							<td class="start color(#000000)">0.09</td>
							<td class="start color(#000000)">99.3%</td>
						</tr>
						<tr>
							<td class="start color(#000000)">Latin incunabula (Springmann et al., 2018)</td>
							<td class="start color(#000000)">99.0%</td>
							<td class="start color(#000000)">0.11</td>
							<td class="start color(#000000)">99.2%</td>
						</tr>
						<tr>
							<td class="start color(#000000)">Fraktur (Springmann et al., 2018)</td>
							<td class="start color(#000000)">99.0%</td>
							<td class="start color(#000000)">0.31</td>
							<td class="start color(#000000)">99.3%</td>
						</tr>
						<tr>
							<td class="start color(#000000)">Cyrillic</td>
							<td class="start color(#000000)">99.3%</td>
							<td class="start color(#000000)">0.15</td>
							<td class="start color(#000000)">99.6%</td>
						</tr>
						<tr>
							<td class="start color(#000000)bold">Manuscripts</td>
							<td/>
							<td/>
							<td/>
						</tr>
						<tr>
							<td class="start color(#000000)">Hebrew 
                  <span id="ftn1_return">
									<a class="notelink" title="Midrash Tanhuma, BNF H√©b 150" href="#ftn1">
										<sup>4</sup>
									</a>
								</span>
							</td>
							<td class="start color(#000000)">96.9%</td>
							<td class="start color(#000000)">-</td>
							<td class="start color(#000000)">-</td>
						</tr>
						<tr>
							<td class="start color(#000000)">Medieval Latin 
                  <span id="ftn0_return">
									<a class="notelink" title="Josephus Latinus, Bamberg 78 with augmentation" href="#ftn0">
										<sup>5</sup>
									</a>
								</span>
							</td>
							<td class="start color(#000000)">98.2%</td>
							<td class="start color(#000000)">-</td>
							<td class="start color(#000000)">-</td>
						</tr>
					</table>
				</div>
				<div class="figure">
					<img src="Pictures/bd9bbcd5083d643b673c7d8fbec928a0.png" alt="Sample output of the script detection on a bilingual French/Arabic page. Note that Eastern Arabic are always classified as Latin text" class="graphic" width="100%"/>
					<div class="caption">Figure 4. Sample output of the script detection on a bilingual French/Arabic page. Note that Eastern Arabic are always classified as Latin text</div>
				</div>
				<p>Kraken has been used on a wide variety of writing systems, achieving uniformly high character accuracy (CER). Sample accuracies for a diverse set of scripts spanning across multiple centuries of printing are shown in Table 1.</p>
				<p>As a special use case we evaluated recognition of text and emphasis in a mixed English and romanized Arabic library catalog on a training set of 350 lines (50 lines in the validation set) resulting in an averaged CER of 99.3% (œÉ=0.16) over 10 runs with 95.38% CER on cursive and text with increased spacing (œÉ=1.46). When using only emphasized text accuracy as the stopping criterium mean accuracy rises to 99.03% (œÉ=0.28).</p>
			</div>
			<!--TEI back-->
			<div class="bibliogr" id="index.xml-back.1_div.1">
				<h2>
					<span class="headingNumber">Appendix A </span>
				</h2>
				<div class="listhead">Bibliography</div>
				<ol class="listBibl">
					<li id="index.xml-bibl-w2536304aab3b3b1b1b3">
						<div class="biblfree">
							<span style="font-weight:bold">Graves, A., Fern√°ndez, S., Gomez, F. and Schmidhuber, J.</span>
            
             (2006). Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks. 
                <span style="font-style:italic">Proceedings of the 23rd International Conference on Machine Learning</span>
            
            . ACM, pp. 369‚Äì376.
          </div>
					</li>
					<li id="index.xml-bibl-w2536304aab3b3b1b1b5">
						<div class="biblfree">
							<span style="font-weight:bold">He, K., Zhang, X., Ren, S. and Sun, J.</span>
            
             (2016). Deep residual learning for image recognition. 
                <span style="font-style:italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</span>
            
            . pp. 770‚Äì778.
          </div>
					</li>
					<li id="index.xml-bibl-w2536304aab3b3b1b1b7">
						<div class="biblfree">
							<span style="font-weight:bold">Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I. and Salakhutdinov, R. R.</span>
            
             (2012). Improving neural networks by preventing co-adaptation of feature detectors. 
                <span style="font-style:italic">ArXiv Preprint ArXiv:1207.0580</span>
            
            .
          </div>
					</li>
					<li id="index.xml-bibl-w2536304aab3b3b1b1b9">
						<div class="biblfree">
							<span style="font-weight:bold">Kiessling, B., Miller, M. T., Maxim, G., Savant, S. B. and others</span>
            
             (2017). Important New Developments in Arabographic Optical Character Recognition (OCR). 
                <span style="font-style:italic">Al- øU·π£≈´r Al-Wus·π≠ƒÅ</span>
            
            , 
                <span style="font-weight:bold">25</span>
            
            : 1‚Äì13.
          </div>
					</li>
					<li id="index.xml-bibl-w2536304aab3b3b1b1c11">
						<div class="biblfree">
							<span style="font-weight:bold">Kiessling, B., Stoekl Ben Ezra, Daniel and Miller, Matthew Thomas</span>
            
             (2019). BADAM: A Public Dataset for Baseline Detection in Arabic-script Manuscripts.
          </div>
					</li>
					<li id="index.xml-bibl-w2536304aab3b3b1b1c13">
						<div class="biblfree">
							<span style="font-weight:bold">Ronneberger, O., Fischer, P. and Brox, T.</span>
            
             (2015). U-net: Convolutional networks for biomedical image segmentation. 
                <span style="font-style:italic">International Conference on Medical Image Computing and Computer-Assisted Intervention</span>
            
            . Springer, pp. 234‚Äì241.
          </div>
					</li>
					<li id="index.xml-bibl-w2536304aab3b3b1b1c15">
						<div class="biblfree">
							<span style="font-weight:bold">Springmann, U., Reul, C., Dipper, S. and Baiter, J.</span>
            
             (2018). Ground Truth for training OCR engines on historical documents in German Fraktur and Early Modern Latin. 
                <span style="font-style:italic">ArXiv Preprint ArXiv:1809.05501</span>
            
            .
          </div>
					</li>
				</ol>
			</div>
			<!--Notes in [TEI]-->
			<div class="notes">
				<div class="noteHeading">Notes</div>
				<div class="note" id="ftn4">
					<span class="noteLabel">1. </span>
					<div class="noteBody">Mid-20th century printing</div>
				</div>
				<div class="note" id="ftn3">
					<span class="noteLabel">2. </span>
					<div class="noteBody">Late-19th century printing in Ser·π≠ƒÅ form</div>
				</div>
				<div class="note" id="ftn2">
					<span class="noteLabel">3. </span>
					<div class="noteBody">Late-19th century printing</div>
				</div>
				<div class="note" id="ftn1">
					<span class="noteLabel">4. </span>
					<div class="noteBody">Midrash Tanhuma, BNF H√©b 150</div>
				</div>
				<div class="note" id="ftn0">
					<span class="noteLabel">5. </span>
					<div class="noteBody">Josephus Latinus, Bamberg 78 with augmentation</div>
				</div>
			</div>
			<hr/>
		</div>
	</body>
</html>
