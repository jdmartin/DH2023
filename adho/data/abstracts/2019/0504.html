<?xml version="1.0"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
		<!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
		<title>Thematic complexity </title>
		<meta name="author" content="Fotis Jannidis , Leonard Konle and Peter Leinen"/>
		<meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
		<meta name="DC.Title" content="Thematic complexity"/>
		<meta name="DC.Type" content="Text"/>
		<meta name="DC.Format" content="text/html"/>
		<link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
		<link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
		<style>
 div.dh2019 { max-width:1000px; margin: auto;}
 body {
       font-family: verdana;
       font-size: 11px;
}
 p {
    font-family: verdana;
    font-size: 11px;
}
</style>
	</head>
	<body>
		<div class="dh2019">
			<img src="https://dev.clariah.nl/files/dh2019/logoos/EP_banner_DH20194.png" alt="DH2019 Utrecht University, The Netherlands" width="100%"/>
			<hr/>
			<br/>
			<div class="stdheader autogenerated">
				<h1 class="maintitle">
					<span class="titlem">Thematic complexity</span>
					<span class="titlem"/>
				</h1>
			</div>
			<div class="stdfooter autogenerated">
				<address>Fotis Jannidis (fotis.jannidis@uni-wuerzburg.de), Würzburg University, Germany und Leonard Konle (leonard.konle@uni-wuerzburg.de), Würzburg University, Germany und Peter Leinen (P.Leinen@dnb.de), German National Library</address>
			</div>
			<br/>
			<div class="dhconvalidator-xml-link"/>
			<!--TEI front-->
			<!--TEI body-->
			<div class="DH-Heading1" id="index.xml-body.1_div.1">
				<h2 class="DH-Heading1">
					<span class="headingNumber">1. </span>
					<span class="head">
						<a id="id_docs-internal-guid-01115721-7fff-445b-4e04-849c1cd2da34">
							<!--anchor-->
						</a>
          
          1. Introduction
        </span>
				</h2>
				<p>Readers of literary texts have an impression of its complexity, and professional readers like literary critics often use if not the term, but the concept as a basis for their evaluation of literary texts. Recent attempts in literary studies to explore the notion had difficulties agreeing on a definition (Koschorke 2017), a fate which we try to avoid by relying on a very general understanding of complexity: the number of elements and the number and quality of their relations. When we are talking about texts these elements can be words, syllables, metaphors, intertextual relations, the syntax of sentences, themes and topics etc. In this perspective text complexity becomes a multi-dimensional phenomenon. We should emphasize that we are talking about a set of textual features and not about the difficulty for a reader to process the text, which is the domain of cognitive reader studies. Our attempt in this paper to describe a useful approach to thematic complexity in fiction is part of our ongoing research on the complexity of fiction. In Jannidis et. al. (2019) we looked at measures of vocabulary richness and syntactic complexity and applied them to the same collection of popular genre novels and the collection of literature of renowned German writers we are analyzing in this paper. Surprisingly with the exception of sentence length there is no single measure which allows to distinguish consistently between these two collections. This study now looks at thematic complexity. Obviously there is no limit to the themes and topics a novel can deal with, but an infinite amount is difficult to measure. So we use the mixture of genres in documents as a proxy for thematic complexity, and we measure this mixture using topic modeling and Zeta to describe the genres.</p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.2">
				<h2 class="DH-Heading1">
					<span class="headingNumber">2. </span>
					<span class="head">2. Cooperation with the German National Library</span>
				</h2>
				<p>The analysis is based on the digital texts delivered to the German National Library (DNB). The DNB collects, archives, records and makes available to the public the media works published in Germany since 1913 as well as the German-language media works published abroad. Since 2006, the collection of media works published online has also been one of DNB's tasks. </p>
				<p>DNB's holdings currently comprise of more than 5 million digital objects, including some 900,000 e-books, around 1.5 million e-journal editions and about 2 million e-paper editions. In addition to the extensive physical inventory, DNB users have a growing pool of "born digital" objects at their disposal.</p>
				<p>The cooperation with the DH communities is a strategically important continuation of DNB's range of services. One aspect is the support of selected cooperation partners through the provision of even extensive corpora, primarily from born digital objects such as e-books, for carrying out automatic analyses in the DNB labs on site.</p>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.3">
				<h2 class="DH-Heading1">
					<span class="headingNumber">3. </span>
					<span class="head">3. Corpus</span>
				</h2>
				<p>Our corpus holds 9000 novels from 13 pulp fiction genres and high brow literature novels from prize-winning authors (see Fig. 1). </p>
				<p>
					<a id="id_docs-internal-guid-e5c955cf-7fff-cbc6-ff3a-1f0210fac822">
						<!--anchor-->
					</a>
				</p>
				<div class="figure">
					<img src="Pictures/b49679ab6ad88f550d6bea7dff115148.png" alt=" Novels per genre in corpus " class="graphic" width="100%"/>
					<div class="caption">Figure 1. Novels per genre in corpus</div>
				</div>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.4">
				<h2 class="DH-Heading1">
					<span class="headingNumber">4. </span>
					<span class="head">
						<a id="id_docs-internal-guid-49e04944-7fff-c539-e3bc-5b1de0377f29">
							<!--anchor-->
						</a>
          
          4. Methods
        </span>
				</h2>
				<p>
					<span style="color:#000000">We aim to compute thematic complexity on the mixture of genres in documents. Since genre labels for documents are provided we will use these to identify word fields covering stereotypic themes, topoi or motives in genres. For this task, we use Zeta </span>
					<span style="color:#000000">(Schöch et al., 2018) </span>
					<span style="color:#000000">and LDA </span>
					<span style="color:#000000">(Blei et al., 2003)</span>
					<span style="color:#000000">. In a second step, the words are used to measure a distribution of genres in each novel. </span>
				</p>
				<div class="DH-Heading2" id="index.xml-body.1_div.4_div.1">
					<h3 class="DH-Heading2">
						<span class="headingNumber">4.1. </span>
						<span class="head">4.1 Zeta</span>
					</h3>
					<p>Originally, Zeta is used to determine which words are well suited for distinguishing two groups of texts, for example, texts by two authors. However, we are only interested in which words are characteristic of a group. This is why we compare a homogeneous group of texts of one genre with a heterogeneous group to represent the entire corpus.</p>
					<p>
						<span style="color:#000000">The zeta scores of word </span>
						<span style="color:#000000">x</span>
						<span style="color:#000000"/>
						<span style="color:#000000">for each genre are multiplied by the frequency it appears within a document. To represent a document by a single vector, the average scores overall words are computed.</span>
					</p>
					<p>We will use variants of zeta as listed by Schöch et al. (2018), see Table 1.</p>
					<div class="table" id="Table1">
						<table class="frame" style="border-collapse:collapse;border-spacing:0;">
							<tr>
								<td colspan="5" class="center">Table 1: Variants of zeta from (Schöch et al. 2018)</td>
							</tr>
							<tr>
								<td/>
								<td colspan="2">document proportions</td>
								<td colspan="2">relative frequencies</td>
							</tr>
							<tr>
								<td/>
								<td>no transformation</td>
								<td>
									<p>log2-</p>
									<p>Transformation</p>
								</td>
								<td>no Transformation</td>
								<td>
									<p>log2-</p>
									<p>Transformation</p>
								</td>
							</tr>
							<tr>
								<td>Subtraction</td>
								<td>sd0</td>
								<td>sd2</td>
								<td>sr0</td>
								<td>sr2</td>
							</tr>
							<tr>
								<td>Division</td>
								<td>dd0</td>
								<td>dd2</td>
								<td>dr0</td>
								<td>dr2</td>
							</tr>
						</table>
					</div>
				</div>
				<div class="DH-Heading2" id="index.xml-body.1_div.4_div.2">
					<h3 class="DH-Heading2">
						<span class="headingNumber">4.2. </span>
						<span class="head">
							<a id="id_docs-internal-guid-457843fc-7fff-1762-bfbf-2c96780d4515">
								<!--anchor-->
							</a>
            
            4.2 Topic Model
          </span>
					</h3>
					<p>
						<span style="color:#000000">We use the LDA implementation Mallet </span>
						<span style="color:#000000">(McCallum, 2002)</span>
						<span style="color:#000000"/>
						<span style="color:#000000">to compute Topic Models with 50, 100, 150, 200 and 250 topics by 1000 iterations over our corpus. We use the same stopwords as in the zeta pipeline. For each topic a genre distribution is calculated from genre labels and this distribution is used to infer the distribution of genre in documents via their share of topics (see Fig.2). Because every topic contains all words and every document inherits all topics to some extent we set a threshold of 5% proportion for topics in documents to be taken into account.</span>
					</p>
					<p>
						<a id="id_docs-internal-guid-580bd8c5-7fff-24d3-2b03-edd8b98ec205">
							<!--anchor-->
						</a>
					</p>
					<div class="figure">
						<img src="Pictures/933f120b61caf1fcee26afda0d4973e0.png" alt=" From Topic Model to genre distribution " class="graphic" width="100%"/>
						<div class="caption">Figure 2. From Topic Model to genre distribution</div>
					</div>
				</div>
				<div class="DH-Heading2" id="index.xml-body.1_div.4_div.3">
					<h3 class="DH-Heading2">
						<span class="headingNumber">4.3. </span>
						<span class="head">
							<a id="id_docs-internal-guid-4a00d9b6-7fff-92a4-bed2-5f0e11ae5ee5">
								<!--anchor-->
							</a>
            
            4.3 Complexity
          </span>
					</h3>
					<p>Both approaches create a representation of documents as vectors with one dimension for each genre. To measure thematic complexity, we will use the Gini-Index (Giovanni Bellù and Liberati 2006). This measure of dispersion is commonly seen in economics to quantify inequality in income. The values for the Gini-Index lie between 0, which indicates that all incomes are equal or in our context that all genres contribute equally to this text, and 1 (for large numbers), which means that only one person has any income or in our context that only one genre contributes to the document. But in this form a higher value would actually mean lower complexity, so for better readability, we will use the inverse Gini-Index, so a lower value indicates usage of mainly one genre’s vocabulary and a higher one the occurrence of words from different genres.</p>
				</div>
				<div class="DH-Heading2" id="index.xml-body.1_div.4_div.4">
					<h3 class="DH-Heading2">
						<span class="headingNumber">4.4. </span>
						<span class="head">4.4 Evaluation</span>
					</h3>
					<p>There is no way for us to evaluate thematic complexity scores directly because creating test data by humans would be quite time-intensive and of uncertain success. Instead, we will use genre classification as a downstream task with our document representation (see 4.1, 4.2) as input feature, to at least evaluate the genre distribution in documents, on which thematic complexity is based.</p>
				</div>
			</div>
			<div class="DH-Heading1" id="index.xml-body.1_div.5">
				<h2 class="DH-Heading1">
					<span class="headingNumber">5. </span>
					<span class="head">5. Results</span>
				</h2>
				<p>Evaluation results of genre classification (see table 2) show best results for LDA with 150 Topics. The following results, except the most distinctive words in table 3, are all based on this setup. </p>
				<div class="table" id="Table2">
					<table class="frame" style="border-collapse:collapse;border-spacing:0;">
						<tr>
							<td colspan="9" class="center">Table 2: f1 score (weighted) of genre classification with logistic regression</td>
						</tr>
						<tr>
							<td colspan="9" class="center">Zeta</td>
						</tr>
						<tr>
							<td class="center">Variant</td>
							<td class="center">sd0</td>
							<td class="center">dd0</td>
							<td class="center">sd2</td>
							<td class="center">dd2</td>
							<td class="center">sr0</td>
							<td class="center">dr0</td>
							<td class="center">sr2</td>
							<td class="center">dr2</td>
						</tr>
						<tr>
							<td class="center">f1</td>
							<td class="center">.86</td>
							<td class="center">.62</td>
							<td class="center">.86</td>
							<td class="center">.83</td>
							<td class="center">.72</td>
							<td class="center">.68</td>
							<td class="center">.73</td>
							<td class="center">.77</td>
						</tr>
						<tr>
							<td colspan="9" class="center">LDA</td>
						</tr>
						<tr>
							<td class="center">Topics</td>
							<td class="center">50</td>
							<td class="center">100</td>
							<td class="center">150</td>
							<td class="center">200</td>
							<td class="center">250</td>
							<td/>
							<td/>
							<td/>
						</tr>
						<tr>
							<td class="center">f1</td>
							<td class="center">.86</td>
							<td class="center">.88</td>
							<td class="center">.89</td>
							<td class="center">.86</td>
							<td class="center">.86</td>
							<td/>
							<td/>
							<td/>
						</tr>
					</table>
				</div>
				<div class="table" id="Table3">
					<table class="frame" style="border-collapse:collapse;border-spacing:0;">
						<tr>
							<td colspan="4" class="center">Table 3: Most distinctive words per genre (Zeta, sd2)</td>
						</tr>
						<tr>
							<td class="center">Regional</td>
							<td class="center">Western</td>
							<td class="center">High Lit.</td>
							<td class="center">Medical</td>
						</tr>
						<tr>
							<td>
								<p>tavern</p>
								<p>cows</p>
								<p>salute </p>
								<p>mountain rescue</p>
							</td>
							<td>
								<p>ride</p>
								<p>gun</p>
								<p>pasture</p>
								<p>bridle</p>
							</td>
							<td>
								<p>so-called</p>
								<p>jewish</p>
								<p>earth (de: Erden)</p>
								<p>philosophy</p>
							</td>
							<td>
								<p>surgery</p>
								<p>jealous</p>
								<p>eat</p>
								<p>sob</p>
							</td>
						</tr>
					</table>
				</div>
				<p>
					<a id="id_docs-internal-guid-289e7705-7fff-102f-713c-14c3e3242117">
						<!--anchor-->
					</a>
					<span style="color:#000000">Figure </span>
					<span style="color:#000000">3</span>
					<span style="color:#000000">shows the transformation of document vectors consisting of the 14 genre proportions into a 2-dimensional representation. The calculation was done with Uniform Manifold Approximation </span>
					<span style="color:#000000">(McInnes et al. 2018).</span>
				</p>
				<p>
					<a id="id_docs-internal-guid-5244313d-7fff-4988-12bf-6dfce6794356">
						<!--anchor-->
					</a>
				</p>
				<div class="figure">
					<img src="Pictures/ce9fa123c638bf8b2a2a388b7f7ddd83.png" alt=" Umap transformation of genre distribution " class="graphic" width="100%"/>
					<div class="caption">Figure 3. Umap transformation of genre distribution</div>
				</div>
				<p>
					<a id="id_docs-internal-guid-f790b12c-7fff-00fd-cb8b-d158a829087e">
						<!--anchor-->
					</a>
        
        Figure 4 shows the distribution of genres in genres. Naturally the most prominent genre in each genre is its own class. But it shows that there are - as expected - strong intersections between royal, medical, family and love genres.
      </p>
				<p>
					<a id="id_docs-internal-guid-54d704a0-7fff-3200-478c-a20c33201f84">
						<!--anchor-->
					</a>
				</p>
				<div class="figure">
					<img src="Pictures/76c37155d559c42f7325a143aa604c22.png" alt=" Genre proportions heatmap " class="graphic" width="100%"/>
					<div class="caption">Figure 4. Genre proportions heatmap</div>
				</div>
				<p>
					<a id="id_docs-internal-guid-9fefab25-7fff-e60d-94e7-22fb6abd4f06">
						<!--anchor-->
					</a>
        
        Figure 5 shows the change in genre distribution of a mixed genre like western with erotic elements compared to its straight main genre, in this case western. Label for these crossover genres are provided by publishers.
      </p>
				<p>
					<a id="id_docs-internal-guid-f795ae73-7fff-db83-de58-e0148c150626">
						<!--anchor-->
					</a>
				</p>
				<div class="figure">
					<img src="Pictures/2f48c2cdf2b3eac5e2b8e2f095dd45be.png" alt=" Changes in genre distribution of mixed genres relative to main genre " class="graphic" width="100%"/>
					<div class="caption">Figure 5. Changes in genre distribution of mixed genres relative to main genre</div>
				</div>
				<p>
					<a id="id_docs-internal-guid-87ff15f8-7fff-3bb6-daac-e406eb4eb0f5">
						<!--anchor-->
					</a>
				</p>
				<div class="figure">
					<img src="Pictures/9cc2c4a187b59a843e08bcf9cd18c77b.png" alt=" Inverted Gini-Index of novels per genre " class="graphic" width="100%"/>
					<div class="caption">Figure 6. Inverted Gini-Index of novels per genre</div>
				</div>
				<p>
					<a id="id_docs-internal-guid-37a04206-7fff-e403-2e50-acc88162ce80">
						<!--anchor-->
					</a>
        
        Figure 6 shows the inverted Gini-Index, which we propose as a measure of thematic complexity. High Literature, Science Fiction and Crime form a leading group, Love and Adventure novels show high diversity and the war genre seems to be the most monothematic group of texts.
      </p>
			</div>
			<div class="DH-Heading" id="index.xml-body.1_div.6">
				<h2 class="DH-Heading">
					<span class="headingNumber">6. </span>
					<span class="head">6. Discussion and future work</span>
				</h2>
				<p>We have shown two approaches to calculating genre distributions, with LDA doing slightly better in downstream evaluation than Zeta. Based on this results, we were able to use the Gini index to calculate thematic complexity. Our assumption that high literature is constituted from a broader spectrum of subject areas than pulp fiction genres is confirmed.</p>
				<p>Because Zeta and LDA are so close to each other, it seems promising to us to combine both methods, for example, to initialize GuidedLDA with Zeta seed words. </p>
				<p>An intermediate product of the calculation with Zeta are word vectors whose dimension represents the distinctiveness of a word for a genre. Considering this as a naive word embedding it seems almost obvious to redefine the whole workflow by learning word embeddings together with genre classification task.</p>
			</div>
			<!--TEI back-->
			<div class="bibliogr" id="index.xml-back.1_div.1">
				<h2>
					<span class="headingNumber">Appendix A </span>
				</h2>
				<div class="listhead">Bibliography</div>
				<ol class="listBibl">
					<li id="index.xml-bibl-w3726aab3b3b1b1b3">
						<div class="biblfree">
							<a id="id_docs-internal-guid-cec9f849-7fff-870f-3828-08719cef3df0">
								<!--anchor-->
							</a>
							<span style="color:#000000">David M. Blei, Andrew Y. Ng, and Micheal I. Jordan. 2003. Latent Dirichlet Allocation. </span>
							<span style="color:#000000">Journal of Machine Learning Research</span>
							<span style="color:#000000">, 3:993–1022.</span>
						</div>
					</li>
					<li id="index.xml-bibl-w3726aab3b3b1b1b5">
						<div class="biblfree">Lorenzo Giovanni Bellù and Paolo Liberati. 2006. Inequality Analysis. The Gini-Index.</div>
					</li>
					<li id="index.xml-bibl-w3726aab3b3b1b1b7">
						<div class="biblfree">
							<span style="color:#000000">Albrecht Koschorke. 2017. Einleitung. In </span>
							<span style="color:#000000">Komplexität und Einfachheit</span>
							<span style="color:#000000">, pages 1–10. Metzler, Stuttgart.</span>
						</div>
					</li>
					<li id="index.xml-bibl-w3726aab3b3b1b1b9">
						<div class="biblfree">
							<span style="color:#000000">Andrew Kachites McCallum. 2002. </span>
							<span style="color:#000000">MALLET: A Machine Learning for Language Toolkit.</span>
						</div>
					</li>
					<li id="index.xml-bibl-w3726aab3b3b1b1c11">
						<div class="biblfree">
							<span style="color:#000000">Lelland McInnes, John Healy, Nathaniel Saul, and Lukas Großberger. 2018. UMAP: Uniform Manifold Approximation and Projection. </span>
							<span style="color:#000000">The Journal of Open Source Software</span>
							<span style="color:#000000">, 3(29).</span>
						</div>
					</li>
					<li id="index.xml-bibl-w3726aab3b3b1b1c13">
						<div class="biblfree">
							<span style="color:#000000">Christof Schöch, Daniel Schlör, Albin Zehe, Gebhart Henning, Martin Becker, and Andreas Hotho. 2018. Burrows ​Zeta: Exploring​ and​ Evaluating Variants​ ​and​ ​Parameters. In </span>
							<span style="color:#000000">Conference Abstracts of DH2018</span>
							<span style="color:#000000">, Mexico City. ADHO.</span>
						</div>
					</li>
					<li id="index.xml-bibl-w3726aab3b3b1b1c15">
						<div class="biblfree">
							<span style="color:#000000">Fotis Jannidis, Leonard Konle, Peter Leinen. 2019. Makroanalytische Untersuchung von Heftromanen. In </span>
							<span style="color:#000000">Book of Abstracts of DHd2019</span>
							<span style="color:#000000">, Frankfurt a.M.</span>
						</div>
					</li>
				</ol>
			</div>
			<hr/>
		</div>
	</body>
</html>
