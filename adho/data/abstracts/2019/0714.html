<?xml version="1.0"?>
<html xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
	<head>
		<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
		<!--THIS FILE IS GENERATED FROM AN XML MASTER. DO NOT EDIT (5)-->
		<title>The Leonardo Code: Deciphering 50 Years of Artistic/Scientific Collaboration in the Texts and Images of Leonardo Journal, 1968-2018 </title>
		<meta name="author" content="Clarisse Bardiot , Peter Broadwell , Mila Oiva , Pablo Suarez , and Melvin Wevers"/>
		<meta name="generator" content="Text Encoding Initiative Consortium XSLT stylesheets"/>
		<meta name="DC.Title" content="The Leonardo Code: Deciphering 50 Years of Artistic/Scientific Collaboration in the Texts and Images of Leonardo Journal, 1968-2018"/>
		<meta name="DC.Type" content="Text"/>
		<meta name="DC.Format" content="text/html"/>
		<link href="http://www.tei-c.org/release/xml/tei/stylesheet/tei.css" rel="stylesheet" type="text/css"/>
		<link rel="stylesheet" media="print" type="text/css" href="http://www.tei-c.org/release/xml/tei/stylesheet/tei-print.css"/>
		<style>
 div.dh2019 { max-width:1000px; margin: auto;}
 body {
       font-family: verdana;
       font-size: 11px;
}
 p {
    font-family: verdana;
    font-size: 11px;
}
</style>
	</head>
	<body>
		<div class="dh2019">
			<img src="https://dev.clariah.nl/files/dh2019/logoos/EP_banner_DH20194.png" alt="DH2019 Utrecht University, The Netherlands" width="100%"/>
			<hr/>
			<br/>
			<div class="stdheader autogenerated">
				<h1 class="maintitle">
					<span class="titlem">The Leonardo Code: Deciphering 50 Years of Artistic/Scientific Collaboration in the Texts and Images of Leonardo Journal, 1968-2018</span>
					<span class="titlem"/>
				</h1>
			</div>
			<div class="stdfooter autogenerated">
				<address>Clarisse Bardiot (clarisse_bardiot@mac.com), Université Polytechnique Hauts-de-France and Peter Broadwell (broadwell@library.ucla.edu), UCLA and Mila Oiva (milaoiv@utu.fi), University of Turku and Pablo Suarez (pablo@im.unam.mx), UNAM and Melvin Wevers (melvinwevers@gmail.com), KNAW Humanities Cluster</address>
			</div>
			<br/>
			<div class="dhconvalidator-xml-link"/>
			<!--TEI front-->
			<!--TEI body-->
			<p>In 1959, C.P. Snow gave an influential lecture on the split between the two academic cultures – the sciences and the humanities (Snow, 1959). Snow deplored the growing divorce between these worlds and their inability to enter into a dialogue. Nonetheless, around the same period, collaborations between art, science and technology began to develop (Debatty and Grover, 2011) . Snow’s address, which was widely publicized and commented upon (Lee, 2004; Goodyear, 2004), shows that these collaborations cannot be taken for granted. From the 1960s to the present, collaborations between art, science, and technology flourished, leading to the establishment of dedicated cultural institutions and programs, university departments, and academic journals. Among them is 
          <span style="font-style:italic">Leonardo</span>
      
       (1968-present), published by MIT Press, which aims to be a forum for interaction, collaboration, and the sharing of ideas between artists, scientists, and engineers across the globe. The spirit of the journal was inspired by the multifaceted activities or Renaissance polymath Leonardo da Vinci, and by the modern utopian vision of bringing together the best minds of humankind. 
          <span style="font-style:italic">Leonardo</span>
      
       is the leading international peer-reviewed publication on the relationship between art, science and technology, making it an ideal dataset to analyze the emergence and dynamics of such complex collaborations.
    </p>
			<p>This research studies how interactions between art, science, and technology in 
          <span style="font-style:italic">Leonardo</span>
      
       evolved between 1968 and 2018. We use the approximately 3,100 articles and around 7,800 illustrations in the 232 digitized issues of the journal and their metadata as our source data set. Each document is available as a PDF file with full-text searching and an accompanying XML file containing the document’s publication metadata.
    </p>
			<p>While text analysis remains dominant, image and other media analysis is an emerging field that may offer unexpected insight, especially where the arts are concerned (Fyfe and Ge, 2018; Wevers and Smits, 2019). This short paper relies on metadata, text (articles, captions) and images (photographs, diagrams, sketches) to offer a fuller examination of the development and interactions networks between communities of researchers and artists in the journal. We applied multiple analytical approaches to the different materials in the dataset. For example, we analyzed illustrations, topical evolution and semantic transformations within the text, and cross-referenced respective results. We also studied the shifting dynamics of the author/institution network interactions collaborations over time.</p>
			<p>To study the visualizations, we isolated 7,836 illustrations from all issues of the journal using the PDF Figures 2.0 open-source package, which is based on PDFBox tool for parsing scholarly publications 
          <span id="ftn1_return">
					<a class="notelink" title="" href="#ftn1">
						<sup>1</sup>
					</a>
				</span>
      
      . We examined the features of the images in order to determine which modes of representing (and actually doing) art, science or engineering were represented in the images. To this end, we used visual and conceptual clustering based on automatic feature extraction from the images. We ran the PixPlot tool (figure 1) on the images to perform the feature extraction and feature-based similarity clustering; PixPlot uses an 
          <a class="link_ref" href="https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf"/>
      
      Inception3 Convolutional Neural Network, trained on the 
          <a class="link_ref" href="http://image-net.org/challenges/LSVRC/2012/"/>
      
      ImageNet 2012 
          <sup/>
				<span id="ftn2_return">
					<a class="notelink" title="" href="#ftn2">
						<sup>2</sup>
					</a>
				</span>
				<sup/>
      
       data set, and projects its similarity inference results into a two-dimensional manifold with the 
          <a class="link_ref" href="https://github.com/lmcinnes/umap"/>
      
      UMAP algorithm 
          <sup/>
				<span id="ftn3_return">
					<a class="notelink" title="" href="#ftn3">
						<sup>3</sup>
					</a>
				</span>
				<sup/>
      
       such that similar images appear proximate to one another 
          <sup/>
				<span id="ftn4_return">
					<a class="notelink" title="" href="#ftn4">
						<sup>4</sup>
					</a>
				</span>
				<sup/>
      
      . The algorithm allowed us to identify 16 individual clusters that could be considered as lying along a visual genre continuum from “art” to “science,” including archetypes such as technical diagrams, portraits, installations, and sketches. Some clusters are strongly oriented towards “science” or “art,” while others exhibit a mixture of both genre polarities, such as one that weaves kinetic art displays together with more scientific optical imaging devices like radar readouts. Some clustering is representative of periods of time: for example, illustrations from the 1970s exhibit a strong association of technical computer science and engineering diagrams with the notion of “science.” Other features remain constant from the 1950s to the present: for example, portraits of the people involved in the projects, photographs of the installations, standard scientific figures. To understand the longitudinal evolution of our image corpus we will adapt some functionalities of the SIAMESE toolkit 
          <sup/>
				<span id="ftn5_return">
					<a class="notelink" title="" href="#ftn5">
						<sup>5</sup>
					</a>
				</span>
				<sup/>
      
      , which visualizes changes in advertisements over time.
    </p>
			<p>As a next step, we will tag the images according to their clusters to determine, as with a latent text topic modeling approach, the proportion of each “class” of images that is present in each paper. This information can subsequently be paired with the information generated through text mining methods. We will use both unsupervised (LDA, NMF) and supervised (Naive Bayes) clustering techniques to determine to what extent a text fell within the arts or science domain 
          <sup/>
				<span id="ftn6_return">
					<a class="notelink" title="SKlearn and Spacy were used for clustering and NLP." href="#ftn6">
						<sup>6</sup>
					</a>
				</span>
				<sup/>
      
      . Moreover, we will extract entities (locations, organizations, people, works of art) and other linguistic features from the text. Pairing the information gathered from the image and text analysis will allow us to answer questions like: in an article describing an art/science collaboration, is it customary to include representative “art” and “science” images, and if so, do these types appear in similar or dissimilar proportions? Also, we will be able to see whether specific actors or networks of actors were responsible for advancing particular visual styles.
    </p>
			<div class="figure">
				<img src="Pictures/a01788912637b72e327c867aa47c23a2.png" alt="" class="graphic" width="100%"/>
			</div>
			<p>Figure 1: Overview of the 
          <span style="font-style:italic">Leonardo</span>
      
       images dataset as visualized via PixPlot.
    </p>
			<!--TEI back-->
			<!--Notes in [TEI]-->
			<div class="notes">
				<div class="noteHeading">Notes</div>
				<div class="note" id="ftn1">
					<span class="noteLabel">1. </span>
					<div class="noteBody">
						<a class="link_ptr" href="http://pdffigures2.allenai.org/">
							<span>http://pdffigures2.allenai.org/</span>
						</a>
					</div>
				</div>
				<div class="note" id="ftn2">
					<span class="noteLabel">2. </span>
					<div class="noteBody">
						<a class="link_ptr" href="http://image-net.org/challenges/LSVRC/2012/">
							<span>http://image-net.org/challenges/LSVRC/2012/</span>
						</a>
					</div>
				</div>
				<div class="note" id="ftn3">
					<span class="noteLabel">3. </span>
					<div class="noteBody">
						<a class="link_ptr" href="https://github.com/lmcinnes/umap">
							<span>https://github.com/lmcinnes/umap</span>
						</a>
					</div>
				</div>
				<div class="note" id="ftn4">
					<span class="noteLabel">4. </span>
					<div class="noteBody">
						<a class="link_ptr" href="https://github.com/YaleDHLab/pix-plot">
							<span>https://github.com/YaleDHLab/pix-plot</span>
						</a>
					</div>
				</div>
				<div class="note" id="ftn5">
					<span class="noteLabel">5. </span>
					<div class="noteBody">
						<a class="link_ptr" href="http://lab.kb.nl/tool/siamese#live-demo">
							<span>http://lab.kb.nl/tool/siamese#live-demo</span>
						</a>
					</div>
				</div>
				<div class="note" id="ftn6">
					<span class="noteLabel">6. </span>
					<div class="noteBody">SKlearn and Spacy were used for clustering and NLP.</div>
				</div>
			</div>
			<hr/>
		</div>
	</body>
</html>
